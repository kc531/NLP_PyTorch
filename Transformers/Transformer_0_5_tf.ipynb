{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sf8kIKvdh1V8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4w2iwCggb0pn"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        x = self.fc_2(x)        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zuNLGeial48E"
      },
      "outputs": [],
      "source": [
        "class SelfAtt(nn.Module):\n",
        "  def __init__(self, emb_size, heads,dropout):\n",
        "    super(SelfAtt,self).__init__()\n",
        "    self.emb_size = emb_size\n",
        "    self.heads = heads\n",
        "    self.head_dim = emb_size//heads\n",
        "    assert(self.head_dim*heads == self.emb_size), \"head_dim*heads != emb_size\"\n",
        "\n",
        "    self.query = nn.Linear(self.emb_size,self.emb_size)\n",
        "    self.key = nn.Linear(self.emb_size,self.emb_size)\n",
        "    self.value = nn.Linear(self.emb_size,self.emb_size)\n",
        "\n",
        "    self.fc_out = nn.Linear(self.head_dim*heads, self.emb_size)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,values,keys,query,mask=None):\n",
        "    N = query.shape[0]\n",
        "    values = self.value(values)\n",
        "    keys = self.key(keys)  \n",
        "    query1 = self.query(query) \n",
        "\n",
        "    values = values.view(N, -1, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    keys = keys.view(N, -1, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    query1 = query1.view(N, -1, self.heads, self.head_dim).permute(0, 2, 1, 3)   \n",
        "\n",
        "    #dot product of keys and query\n",
        "    energy = torch.matmul(query1, keys.permute(0, 1, 3, 2)) / self.scale\n",
        "    #print(energy.shape)\n",
        "\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "      #print(energy)\n",
        "    \n",
        "    attention = torch.softmax(energy, dim= -1)\n",
        "    print(attention)\n",
        "    #print(values.shape)\n",
        "    x = torch.matmul(self.dropout(attention), values)    \n",
        "    x = x.permute(0, 2, 1, 3).contiguous()\n",
        "    out = x.view(N, -1, self.emb_size)\n",
        "    \n",
        "    out =  self.fc_out(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9oeuJAMnuCk-"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,emb_size, heads, dropout, forward_expansion):\n",
        "    super(TransformerBlock,self).__init__()\n",
        "    self.att = SelfAtt(emb_size,heads,dropout)\n",
        "    self.norm1 = nn.LayerNorm(emb_size)\n",
        "    self.norm2 = nn.LayerNorm(emb_size)\n",
        "\n",
        "    self.feed_forward = PositionwiseFeedforwardLayer(emb_size, forward_expansion*emb_size, dropout)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, value, key, query):\n",
        "    att = self.att(value, key, query)\n",
        "    x = self.norm1(query + self.dropout(att))\n",
        "    forward = self.feed_forward(x)\n",
        "    out  = self.norm2(x + self.dropout(forward))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HEiexFCTxhqf"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, \n",
        "               src_vocab_size, \n",
        "               emb_size,\n",
        "               num_layers,\n",
        "               heads,\n",
        "               device,\n",
        "               forward_expansion,\n",
        "               dropout,\n",
        "               max_length,\n",
        "               ):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.emb_size = emb_size\n",
        "    self.device = device\n",
        "    self.word_embedding  = nn.Embedding(src_vocab_size,emb_size)\n",
        "    self.position_embedding = nn.Embedding(max_length, emb_size)\n",
        "    self.layers = nn.ModuleList(\n",
        "        [\n",
        "         TransformerBlock(\n",
        "             emb_size,\n",
        "             heads,\n",
        "             dropout = dropout,\n",
        "             forward_expansion = forward_expansion,\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([emb_size])).to(device)\n",
        "  def forward(self,x):\n",
        "    N,seq_length = x.shape\n",
        "    positions = torch.arange(0, seq_length).unsqueeze(0).repeat(N, 1).to(self.device)\n",
        "    out = self.dropout(self.word_embedding(x)*self.scale + self.position_embedding(positions))\n",
        "    for layer in self.layers:\n",
        "      out  = layer(out,out,out)\n",
        "      \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-AD6srbm3eYj"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, emb_size, heads, forward_expansion, dropout, device):\n",
        "    super(DecoderBlock,self).__init__()\n",
        "    self.attention = SelfAtt(emb_size,heads,dropout)\n",
        "    self.norm1 = nn.LayerNorm(emb_size)\n",
        "    self.norm = nn.LayerNorm(emb_size)\n",
        "    self.transformer_block = TransformerBlock(emb_size, heads, dropout, forward_expansion)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, value, key):\n",
        "    attention = self.attention(x,x,x)\n",
        "    query = self.norm1(self.dropout(attention) + x)\n",
        "    out  = self.transformer_block(value, key, query)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uZFojgCL5fQg"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        trg_vocab_size,\n",
        "        embed_size,\n",
        "        num_layers,\n",
        "        heads,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        device,\n",
        "        max_length,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([embed_size])).to(device)\n",
        "\n",
        "    def forward(self, x, enc_out):\n",
        "        N, seq_length = x.shape\n",
        "        positions = torch.arange(0, seq_length).unsqueeze(0).repeat(N, 1).to(self.device)\n",
        "        x = self.dropout((self.word_embedding(x)*self.scale) + self.position_embedding(positions))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out, enc_out)\n",
        "        out = self.fc_out(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DvUN9vRyJPtK"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        embed_size=5,\n",
        "        num_layers=6,\n",
        "        forward_expansion=4,\n",
        "        heads=1,\n",
        "        dropout=0,\n",
        "        device=\"cpu\",\n",
        "        max_length=10,\n",
        "        src_pad_idx = 0,\n",
        "        trg_pad_idx = 0,\n",
        "        teacher_force = 0.5,\n",
        "    ):\n",
        "\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            src_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            device,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            max_length,\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            trg_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            device,\n",
        "            max_length,\n",
        "        )\n",
        "\n",
        "        self.device = device\n",
        "        self.trg_vocab_size = trg_vocab_size\n",
        "        self.teacher_force = teacher_force\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        enc_src = self.encoder(src)\n",
        "        outputs = torch.zeros((trg.shape[0],trg.shape[1],self.trg_vocab_size)).to(self.device)\n",
        "        trg_dec = trg[:,0:1]\n",
        "        for i in range(trg.shape[1]):\n",
        "            out = self.decoder(trg_dec, enc_src)\n",
        "            outputs[:,i,:] = out[:,-1,:]\n",
        "            trg_dec = torch.argmax(outputs[:,0:i+2,:],dim = 2) if random.random() < self.teacher_force else trg[:,0:i+2]\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(device)\n",
        "    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0]]).to(\n",
        "        device\n",
        "    )\n",
        "    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0]]).to(device)\n",
        "\n",
        "    src_pad_idx = 1\n",
        "    trg_pad_idx = 3\n",
        "    src_vocab_size = 10\n",
        "    trg_vocab_size = 10 \n",
        "    model  = Transformer( src_vocab_size, trg_vocab_size,).to(device)\n",
        "    out = model(x, trg)\n",
        "    print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMAthgr4v9KW",
        "outputId": "02204309-d295-4943-a0c9-bad266ae2fa7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "tensor([[[[1.4548e-01, 2.5826e-04, 7.8264e-03, 1.1178e-04, 1.8012e-04,\n",
            "           4.9817e-04, 1.3810e-04, 8.3550e-01, 1.0006e-02],\n",
            "          [2.4547e-05, 4.3949e-03, 3.4911e-05, 4.7845e-02, 9.4335e-01,\n",
            "           1.9375e-04, 4.0054e-03, 5.3271e-05, 9.3907e-05],\n",
            "          [1.3042e-01, 5.9124e-02, 1.4305e-02, 8.2531e-02, 3.9502e-01,\n",
            "           2.0913e-02, 4.7821e-02, 1.5379e-01, 9.6078e-02],\n",
            "          [3.7214e-05, 4.1774e-01, 1.2315e-03, 1.0910e-02, 2.3462e-02,\n",
            "           1.3337e-01, 4.1000e-01, 1.2799e-06, 3.2424e-03],\n",
            "          [1.1290e-05, 1.6732e-01, 7.1817e-03, 2.2533e-01, 3.2824e-02,\n",
            "           1.5877e-01, 4.0797e-01, 1.2408e-06, 5.9048e-04],\n",
            "          [9.4389e-04, 4.0365e-03, 4.1105e-05, 5.6134e-03, 9.8208e-01,\n",
            "           9.0527e-05, 1.5102e-03, 4.7910e-03, 8.8982e-04],\n",
            "          [2.1466e-05, 1.2921e-02, 2.3758e-05, 2.2060e-02, 9.5548e-01,\n",
            "           3.9910e-04, 8.8980e-03, 1.9516e-05, 1.8077e-04],\n",
            "          [2.8297e-01, 5.9892e-04, 3.3723e-01, 9.2095e-04, 1.4994e-05,\n",
            "           2.0373e-02, 1.0818e-03, 3.2272e-01, 3.4092e-02],\n",
            "          [1.0265e-01, 1.5287e-02, 6.5726e-03, 1.6036e-02, 2.7551e-01,\n",
            "           2.9549e-03, 7.1300e-03, 5.4422e-01, 2.9637e-02]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0920, 0.1104, 0.1098, 0.1448, 0.1203, 0.1159, 0.1224, 0.0879,\n",
            "           0.0964],\n",
            "          [0.1292, 0.1078, 0.0898, 0.0879, 0.0868, 0.1403, 0.1088, 0.0764,\n",
            "           0.1730],\n",
            "          [0.1376, 0.0771, 0.1247, 0.1384, 0.0720, 0.1569, 0.0950, 0.0812,\n",
            "           0.1172],\n",
            "          [0.1245, 0.0641, 0.1867, 0.1491, 0.0534, 0.1734, 0.0837, 0.0828,\n",
            "           0.0824],\n",
            "          [0.1576, 0.0740, 0.1539, 0.1018, 0.0678, 0.1215, 0.0770, 0.1494,\n",
            "           0.0971],\n",
            "          [0.0743, 0.1232, 0.0690, 0.1107, 0.0897, 0.1780, 0.1466, 0.0279,\n",
            "           0.1805],\n",
            "          [0.1190, 0.1032, 0.1002, 0.0995, 0.0782, 0.1624, 0.1123, 0.0625,\n",
            "           0.1629],\n",
            "          [0.1539, 0.0502, 0.1629, 0.1196, 0.0709, 0.0703, 0.0536, 0.2717,\n",
            "           0.0470],\n",
            "          [0.0639, 0.1614, 0.0521, 0.0861, 0.1292, 0.1254, 0.1607, 0.0340,\n",
            "           0.1872]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0667, 0.1024, 0.2086, 0.1318, 0.0862, 0.1464, 0.1100, 0.0810,\n",
            "           0.0670],\n",
            "          [0.1633, 0.0959, 0.0945, 0.0843, 0.0924, 0.0964, 0.0917, 0.1528,\n",
            "           0.1287],\n",
            "          [0.1489, 0.0890, 0.1149, 0.1005, 0.0915, 0.1019, 0.0903, 0.1587,\n",
            "           0.1042],\n",
            "          [0.1476, 0.0986, 0.1077, 0.0919, 0.0925, 0.1067, 0.0964, 0.1363,\n",
            "           0.1223],\n",
            "          [0.1617, 0.1009, 0.0851, 0.0832, 0.0980, 0.0952, 0.0955, 0.1401,\n",
            "           0.1403],\n",
            "          [0.1249, 0.0941, 0.1519, 0.1007, 0.0822, 0.1213, 0.0950, 0.1342,\n",
            "           0.0957],\n",
            "          [0.1569, 0.0967, 0.1025, 0.0864, 0.0906, 0.1015, 0.0931, 0.1473,\n",
            "           0.1250],\n",
            "          [0.1112, 0.1053, 0.1066, 0.1233, 0.1183, 0.1056, 0.1091, 0.1173,\n",
            "           0.1033],\n",
            "          [0.0941, 0.1034, 0.1801, 0.1076, 0.0825, 0.1375, 0.1047, 0.1033,\n",
            "           0.0867]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1562, 0.0567, 0.1017, 0.0601, 0.0758, 0.0401, 0.0436, 0.4217,\n",
            "           0.0441],\n",
            "          [0.0918, 0.0922, 0.0658, 0.1123, 0.0779, 0.1736, 0.1245, 0.0262,\n",
            "           0.2356],\n",
            "          [0.0676, 0.1333, 0.1171, 0.1314, 0.1293, 0.1226, 0.1386, 0.0719,\n",
            "           0.0882],\n",
            "          [0.1424, 0.0828, 0.0882, 0.1167, 0.0849, 0.1372, 0.1001, 0.0704,\n",
            "           0.1772],\n",
            "          [0.1209, 0.0747, 0.0579, 0.0994, 0.0644, 0.1661, 0.1034, 0.0282,\n",
            "           0.2850],\n",
            "          [0.1314, 0.0919, 0.1112, 0.1212, 0.1026, 0.1123, 0.0986, 0.1169,\n",
            "           0.1138],\n",
            "          [0.1140, 0.0837, 0.0700, 0.1138, 0.0762, 0.1640, 0.1118, 0.0352,\n",
            "           0.2312],\n",
            "          [0.0855, 0.1319, 0.1266, 0.0994, 0.1315, 0.0846, 0.1116, 0.1604,\n",
            "           0.0684],\n",
            "          [0.2523, 0.0493, 0.0856, 0.0715, 0.0638, 0.0641, 0.0476, 0.2597,\n",
            "           0.1061]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1036, 0.1115, 0.0727, 0.1417, 0.1720, 0.0764, 0.1136, 0.1025,\n",
            "           0.1061],\n",
            "          [0.0921, 0.0845, 0.1729, 0.1635, 0.0873, 0.1411, 0.0978, 0.0846,\n",
            "           0.0763],\n",
            "          [0.0737, 0.0878, 0.2308, 0.1484, 0.0798, 0.1388, 0.0953, 0.0910,\n",
            "           0.0543],\n",
            "          [0.0649, 0.0684, 0.2714, 0.1942, 0.0757, 0.1263, 0.0794, 0.0832,\n",
            "           0.0366],\n",
            "          [0.0637, 0.1058, 0.1502, 0.1797, 0.1237, 0.1208, 0.1195, 0.0704,\n",
            "           0.0661],\n",
            "          [0.1229, 0.0445, 0.2753, 0.1611, 0.0450, 0.1387, 0.0536, 0.1115,\n",
            "           0.0474],\n",
            "          [0.0966, 0.0661, 0.2210, 0.1743, 0.0682, 0.1454, 0.0791, 0.0893,\n",
            "           0.0599],\n",
            "          [0.0575, 0.1643, 0.0488, 0.1056, 0.2194, 0.0685, 0.1569, 0.0660,\n",
            "           0.1130],\n",
            "          [0.1642, 0.0598, 0.1334, 0.1709, 0.0835, 0.1081, 0.0702, 0.1214,\n",
            "           0.0885]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2441, 0.0469, 0.0478, 0.0654, 0.0418, 0.1415, 0.0602, 0.0929,\n",
            "           0.2593],\n",
            "          [0.0791, 0.1341, 0.0859, 0.1139, 0.2134, 0.0412, 0.1011, 0.1802,\n",
            "           0.0513],\n",
            "          [0.0618, 0.1489, 0.1279, 0.1247, 0.1640, 0.0797, 0.1318, 0.0982,\n",
            "           0.0631],\n",
            "          [0.0901, 0.1280, 0.1040, 0.1222, 0.1545, 0.0796, 0.1170, 0.1220,\n",
            "           0.0824],\n",
            "          [0.1007, 0.1188, 0.0731, 0.1076, 0.1998, 0.0396, 0.0904, 0.2104,\n",
            "           0.0595],\n",
            "          [0.0820, 0.1204, 0.1237, 0.1208, 0.1084, 0.1351, 0.1295, 0.0730,\n",
            "           0.1072],\n",
            "          [0.0752, 0.1389, 0.0995, 0.1217, 0.1947, 0.0548, 0.1132, 0.1436,\n",
            "           0.0584],\n",
            "          [0.2493, 0.0606, 0.0473, 0.0728, 0.0738, 0.0797, 0.0619, 0.1766,\n",
            "           0.1779],\n",
            "          [0.1758, 0.0724, 0.0721, 0.0909, 0.0675, 0.1436, 0.0863, 0.0945,\n",
            "           0.1970]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0491, 0.0976, 0.1356, 0.2248, 0.1835, 0.0778, 0.1349, 0.0537,\n",
            "           0.0430]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0690, 0.1561, 0.1211, 0.1222, 0.1411, 0.0920, 0.1513, 0.0801,\n",
            "           0.0671]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0832, 0.1541, 0.1075, 0.1037, 0.1197, 0.1066, 0.1461, 0.0892,\n",
            "           0.0898]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0663, 0.1954, 0.0696, 0.1077, 0.2135, 0.0471, 0.1488, 0.0908,\n",
            "           0.0609]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0739, 0.1695, 0.0822, 0.0835, 0.0900, 0.1445, 0.1771, 0.0668,\n",
            "           0.1123]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1003, 0.0900, 0.1135, 0.1464, 0.1157, 0.1243, 0.1127, 0.0897,\n",
            "           0.1074]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.6977, 0.3023],\n",
            "          [0.5251, 0.4749]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0866, 0.0761, 0.1775, 0.1790, 0.1264, 0.1027, 0.0946, 0.0907,\n",
            "           0.0664],\n",
            "          [0.1967, 0.0278, 0.1948, 0.0599, 0.0270, 0.1641, 0.0294, 0.1643,\n",
            "           0.1360]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.7025, 0.2975],\n",
            "          [0.5165, 0.4835]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0769, 0.1539, 0.1204, 0.1138, 0.1329, 0.0951, 0.1439, 0.0885,\n",
            "           0.0745],\n",
            "          [0.1311, 0.1227, 0.1002, 0.0812, 0.0998, 0.0994, 0.0999, 0.1407,\n",
            "           0.1250]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.5906, 0.4094],\n",
            "          [0.5646, 0.4354]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0822, 0.1570, 0.1063, 0.1031, 0.1210, 0.1051, 0.1477, 0.0888,\n",
            "           0.0889],\n",
            "          [0.0683, 0.1961, 0.0726, 0.0915, 0.1288, 0.0971, 0.1827, 0.0714,\n",
            "           0.0916]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.4756, 0.5244],\n",
            "          [0.4689, 0.5311]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0647, 0.1995, 0.0688, 0.1064, 0.2065, 0.0500, 0.1552, 0.0867,\n",
            "           0.0622],\n",
            "          [0.0541, 0.2175, 0.0621, 0.0904, 0.1321, 0.0942, 0.2123, 0.0554,\n",
            "           0.0819]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.5001, 0.4999],\n",
            "          [0.4967, 0.5033]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0746, 0.1679, 0.0818, 0.0841, 0.0905, 0.1443, 0.1760, 0.0673,\n",
            "           0.1135],\n",
            "          [0.1024, 0.1349, 0.0928, 0.0923, 0.0996, 0.1246, 0.1322, 0.0976,\n",
            "           0.1237]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.4869, 0.5131],\n",
            "          [0.5006, 0.4994]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1010, 0.0901, 0.1109, 0.1465, 0.1169, 0.1231, 0.1128, 0.0900,\n",
            "           0.1087],\n",
            "          [0.0949, 0.0881, 0.0992, 0.1640, 0.1312, 0.1159, 0.1176, 0.0823,\n",
            "           0.1068]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.5113, 0.2005, 0.2882],\n",
            "          [0.3964, 0.2424, 0.3613],\n",
            "          [0.4013, 0.3654, 0.2333]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0883, 0.0755, 0.1784, 0.1769, 0.1246, 0.1034, 0.0932, 0.0923,\n",
            "           0.0674],\n",
            "          [0.0591, 0.0810, 0.1710, 0.2176, 0.1440, 0.1000, 0.1167, 0.0608,\n",
            "           0.0498],\n",
            "          [0.2155, 0.0289, 0.1688, 0.0526, 0.0271, 0.1464, 0.0278, 0.1850,\n",
            "           0.1478]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.4077, 0.4133, 0.1790],\n",
            "          [0.3950, 0.3864, 0.2185],\n",
            "          [0.3762, 0.3509, 0.2729]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0772, 0.1542, 0.1197, 0.1136, 0.1336, 0.0944, 0.1437, 0.0890,\n",
            "           0.0747],\n",
            "          [0.0761, 0.1517, 0.1267, 0.1143, 0.1289, 0.0984, 0.1434, 0.0873,\n",
            "           0.0731],\n",
            "          [0.1198, 0.1308, 0.1032, 0.0877, 0.1096, 0.0959, 0.1078, 0.1321,\n",
            "           0.1132]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.3684, 0.3235, 0.3081],\n",
            "          [0.3747, 0.3268, 0.2985],\n",
            "          [0.3585, 0.3486, 0.2929]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0808, 0.1593, 0.1057, 0.1031, 0.1220, 0.1042, 0.1496, 0.0876,\n",
            "           0.0877],\n",
            "          [0.0811, 0.1750, 0.0894, 0.0936, 0.1244, 0.0984, 0.1564, 0.0880,\n",
            "           0.0937],\n",
            "          [0.0702, 0.1915, 0.0814, 0.0948, 0.1328, 0.0931, 0.1735, 0.0768,\n",
            "           0.0858]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.3219, 0.3120, 0.3661],\n",
            "          [0.3208, 0.3099, 0.3693],\n",
            "          [0.3188, 0.3082, 0.3731]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0637, 0.2027, 0.0674, 0.1052, 0.2037, 0.0511, 0.1591, 0.0842,\n",
            "           0.0630],\n",
            "          [0.0668, 0.1928, 0.0753, 0.1087, 0.2002, 0.0528, 0.1517, 0.0892,\n",
            "           0.0625],\n",
            "          [0.0566, 0.2165, 0.0612, 0.0925, 0.1433, 0.0852, 0.2037, 0.0601,\n",
            "           0.0809]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.3350, 0.3349, 0.3301],\n",
            "          [0.3346, 0.3339, 0.3315],\n",
            "          [0.3350, 0.3328, 0.3322]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0758, 0.1666, 0.0825, 0.0844, 0.0909, 0.1435, 0.1739, 0.0685,\n",
            "           0.1139],\n",
            "          [0.0731, 0.1703, 0.0823, 0.0836, 0.0901, 0.1447, 0.1783, 0.0661,\n",
            "           0.1115],\n",
            "          [0.0889, 0.1482, 0.0863, 0.0907, 0.0969, 0.1343, 0.1522, 0.0817,\n",
            "           0.1209]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.3314, 0.3398, 0.3288],\n",
            "          [0.3320, 0.3415, 0.3265],\n",
            "          [0.3332, 0.3364, 0.3304]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1002, 0.0898, 0.1106, 0.1482, 0.1177, 0.1229, 0.1132, 0.0891,\n",
            "           0.1082],\n",
            "          [0.1006, 0.0902, 0.1104, 0.1470, 0.1172, 0.1231, 0.1133, 0.0895,\n",
            "           0.1087],\n",
            "          [0.0965, 0.0887, 0.1000, 0.1603, 0.1291, 0.1165, 0.1167, 0.0841,\n",
            "           0.1080]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2923, 0.1529, 0.3428, 0.2120],\n",
            "          [0.8026, 0.0149, 0.0975, 0.0851],\n",
            "          [0.0216, 0.7685, 0.0913, 0.1186],\n",
            "          [0.1080, 0.4600, 0.2097, 0.2223]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0504, 0.1010, 0.1303, 0.2197, 0.1906, 0.0737, 0.1345, 0.0562,\n",
            "           0.0436],\n",
            "          [0.1035, 0.1261, 0.0828, 0.1110, 0.1261, 0.1030, 0.1279, 0.0999,\n",
            "           0.1196],\n",
            "          [0.1471, 0.0374, 0.2119, 0.0883, 0.0376, 0.1930, 0.0471, 0.1188,\n",
            "           0.1188],\n",
            "          [0.1004, 0.0843, 0.1383, 0.1304, 0.0877, 0.1560, 0.1079, 0.0866,\n",
            "           0.1083]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.4137, 0.2112, 0.1826, 0.1925],\n",
            "          [0.2199, 0.3792, 0.1495, 0.2514],\n",
            "          [0.1411, 0.3056, 0.2764, 0.2769],\n",
            "          [0.1749, 0.3825, 0.1791, 0.2634]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0700, 0.1565, 0.1174, 0.1214, 0.1417, 0.0918, 0.1516, 0.0806,\n",
            "           0.0690],\n",
            "          [0.1015, 0.1334, 0.1169, 0.1062, 0.1270, 0.0911, 0.1168, 0.1163,\n",
            "           0.0909],\n",
            "          [0.1496, 0.1078, 0.0961, 0.0735, 0.0872, 0.1022, 0.0865, 0.1550,\n",
            "           0.1420],\n",
            "          [0.1204, 0.1207, 0.1206, 0.0912, 0.1036, 0.1013, 0.1019, 0.1333,\n",
            "           0.1070]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.3286, 0.3053, 0.1628, 0.2033],\n",
            "          [0.2731, 0.2388, 0.2607, 0.2273],\n",
            "          [0.3929, 0.1527, 0.2593, 0.1951],\n",
            "          [0.3826, 0.1808, 0.2483, 0.1884]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0877, 0.1090, 0.1372, 0.1240, 0.0990, 0.1397, 0.1266, 0.0832,\n",
            "           0.0935],\n",
            "          [0.0886, 0.1814, 0.0742, 0.0905, 0.1496, 0.0734, 0.1440, 0.1040,\n",
            "           0.0943],\n",
            "          [0.0657, 0.2032, 0.0583, 0.0857, 0.1239, 0.1008, 0.1962, 0.0640,\n",
            "           0.1022],\n",
            "          [0.0670, 0.2699, 0.0386, 0.0599, 0.1517, 0.0559, 0.1824, 0.0810,\n",
            "           0.0935]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2131, 0.2928, 0.2325, 0.2616],\n",
            "          [0.2353, 0.2802, 0.2470, 0.2374],\n",
            "          [0.1712, 0.3218, 0.2076, 0.2995],\n",
            "          [0.1933, 0.3169, 0.2220, 0.2678]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0607, 0.2100, 0.0584, 0.1027, 0.2300, 0.0408, 0.1546, 0.0852,\n",
            "           0.0576],\n",
            "          [0.1016, 0.1353, 0.0800, 0.0954, 0.1063, 0.1202, 0.1367, 0.0937,\n",
            "           0.1309],\n",
            "          [0.0487, 0.2033, 0.0606, 0.0774, 0.0862, 0.1494, 0.2357, 0.0409,\n",
            "           0.0978],\n",
            "          [0.0801, 0.1136, 0.1159, 0.0863, 0.0590, 0.2178, 0.1436, 0.0626,\n",
            "           0.1210]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2337, 0.2673, 0.2457, 0.2534],\n",
            "          [0.3225, 0.1454, 0.3351, 0.1970],\n",
            "          [0.1711, 0.3777, 0.2065, 0.2447],\n",
            "          [0.2232, 0.2617, 0.3038, 0.2114]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0779, 0.1657, 0.0844, 0.0835, 0.0905, 0.1423, 0.1700, 0.0713,\n",
            "           0.1143],\n",
            "          [0.0505, 0.1765, 0.0609, 0.0902, 0.0886, 0.1604, 0.2291, 0.0395,\n",
            "           0.1042],\n",
            "          [0.1485, 0.0915, 0.1122, 0.0950, 0.1043, 0.0897, 0.0779, 0.1608,\n",
            "           0.1201],\n",
            "          [0.0701, 0.1585, 0.0811, 0.0987, 0.1003, 0.1414, 0.1808, 0.0617,\n",
            "           0.1075]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1963, 0.2197, 0.3151, 0.2689],\n",
            "          [0.1984, 0.2605, 0.2867, 0.2543],\n",
            "          [0.2362, 0.3049, 0.2006, 0.2583],\n",
            "          [0.2407, 0.3056, 0.2045, 0.2491]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1034, 0.0914, 0.1214, 0.1366, 0.1083, 0.1275, 0.1098, 0.0943,\n",
            "           0.1073],\n",
            "          [0.1100, 0.0998, 0.1173, 0.1209, 0.1074, 0.1200, 0.1083, 0.1051,\n",
            "           0.1112],\n",
            "          [0.0888, 0.0893, 0.0935, 0.1746, 0.1417, 0.1105, 0.1228, 0.0767,\n",
            "           0.1021],\n",
            "          [0.1044, 0.1012, 0.0881, 0.1376, 0.1318, 0.1064, 0.1179, 0.0950,\n",
            "           0.1177]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2099, 0.1098, 0.2462, 0.1523, 0.2818],\n",
            "          [0.6875, 0.0128, 0.0835, 0.0729, 0.1434],\n",
            "          [0.0198, 0.7029, 0.0835, 0.1085, 0.0854],\n",
            "          [0.0897, 0.3819, 0.1741, 0.1845, 0.1699],\n",
            "          [0.4058, 0.0536, 0.1479, 0.1078, 0.2849]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0509, 0.1016, 0.1293, 0.2182, 0.1911, 0.0734, 0.1344, 0.0569,\n",
            "           0.0441],\n",
            "          [0.1036, 0.1273, 0.0816, 0.1104, 0.1275, 0.1013, 0.1281, 0.1005,\n",
            "           0.1196],\n",
            "          [0.1471, 0.0375, 0.2112, 0.0883, 0.0377, 0.1930, 0.0473, 0.1188,\n",
            "           0.1190],\n",
            "          [0.1010, 0.0859, 0.1352, 0.1294, 0.0891, 0.1538, 0.1088, 0.0874,\n",
            "           0.1094],\n",
            "          [0.0390, 0.0915, 0.1422, 0.2477, 0.1752, 0.0833, 0.1439, 0.0409,\n",
            "           0.0361]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2949, 0.1506, 0.1279, 0.1358, 0.2909],\n",
            "          [0.1863, 0.3176, 0.1243, 0.2127, 0.1591],\n",
            "          [0.1271, 0.2719, 0.2438, 0.2482, 0.1090],\n",
            "          [0.1587, 0.3334, 0.1508, 0.2299, 0.1271],\n",
            "          [0.2563, 0.1815, 0.1576, 0.1637, 0.2410]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0695, 0.1569, 0.1171, 0.1221, 0.1430, 0.0909, 0.1519, 0.0803,\n",
            "           0.0683],\n",
            "          [0.1001, 0.1342, 0.1164, 0.1074, 0.1287, 0.0904, 0.1180, 0.1149,\n",
            "           0.0898],\n",
            "          [0.1488, 0.1082, 0.0967, 0.0739, 0.0878, 0.1020, 0.0869, 0.1547,\n",
            "           0.1409],\n",
            "          [0.1178, 0.1224, 0.1213, 0.0928, 0.1058, 0.1004, 0.1038, 0.1312,\n",
            "           0.1045],\n",
            "          [0.0717, 0.1521, 0.1268, 0.1192, 0.1322, 0.0981, 0.1480, 0.0820,\n",
            "           0.0698]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2576, 0.2402, 0.1279, 0.1673, 0.2070],\n",
            "          [0.2075, 0.1969, 0.2014, 0.1774, 0.2169],\n",
            "          [0.2773, 0.1077, 0.1850, 0.1380, 0.2920],\n",
            "          [0.2696, 0.1363, 0.1766, 0.1346, 0.2829],\n",
            "          [0.2829, 0.2254, 0.1160, 0.1512, 0.2245]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0870, 0.1131, 0.1362, 0.1225, 0.1016, 0.1351, 0.1283, 0.0842,\n",
            "           0.0918],\n",
            "          [0.0869, 0.1854, 0.0726, 0.0895, 0.1502, 0.0729, 0.1466, 0.1022,\n",
            "           0.0937],\n",
            "          [0.0655, 0.2087, 0.0570, 0.0837, 0.1265, 0.0964, 0.1962, 0.0651,\n",
            "           0.1009],\n",
            "          [0.0674, 0.2685, 0.0401, 0.0607, 0.1532, 0.0555, 0.1805, 0.0823,\n",
            "           0.0916],\n",
            "          [0.0861, 0.1443, 0.1030, 0.1045, 0.1116, 0.1186, 0.1456, 0.0862,\n",
            "           0.1000]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1761, 0.2409, 0.1935, 0.2172, 0.1723],\n",
            "          [0.1908, 0.2292, 0.2008, 0.1984, 0.1808],\n",
            "          [0.1475, 0.2698, 0.1806, 0.2554, 0.1468],\n",
            "          [0.1654, 0.2610, 0.1897, 0.2263, 0.1576],\n",
            "          [0.1704, 0.2485, 0.1906, 0.2240, 0.1666]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0611, 0.2089, 0.0591, 0.1031, 0.2287, 0.0412, 0.1542, 0.0856,\n",
            "           0.0579],\n",
            "          [0.1005, 0.1361, 0.0811, 0.0958, 0.1064, 0.1205, 0.1376, 0.0930,\n",
            "           0.1291],\n",
            "          [0.0494, 0.2002, 0.0626, 0.0781, 0.0854, 0.1519, 0.2330, 0.0414,\n",
            "           0.0981],\n",
            "          [0.0816, 0.1179, 0.1143, 0.0888, 0.0645, 0.2029, 0.1448, 0.0657,\n",
            "           0.1195],\n",
            "          [0.0637, 0.2005, 0.0691, 0.1067, 0.2117, 0.0477, 0.1537, 0.0871,\n",
            "           0.0597]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1911, 0.2146, 0.2007, 0.2029, 0.1907],\n",
            "          [0.2395, 0.1192, 0.2441, 0.1482, 0.2490],\n",
            "          [0.1512, 0.3150, 0.1815, 0.2089, 0.1433],\n",
            "          [0.1907, 0.2096, 0.2430, 0.1710, 0.1858],\n",
            "          [0.1867, 0.2221, 0.2031, 0.2029, 0.1852]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0781, 0.1653, 0.0843, 0.0837, 0.0907, 0.1422, 0.1697, 0.0714,\n",
            "           0.1146],\n",
            "          [0.0500, 0.1778, 0.0607, 0.0895, 0.0880, 0.1607, 0.2306, 0.0391,\n",
            "           0.1037],\n",
            "          [0.1400, 0.0983, 0.1094, 0.0962, 0.1050, 0.0955, 0.0862, 0.1480,\n",
            "           0.1213],\n",
            "          [0.0661, 0.1634, 0.0778, 0.0966, 0.0980, 0.1448, 0.1894, 0.0573,\n",
            "           0.1065],\n",
            "          [0.0770, 0.1671, 0.0856, 0.0836, 0.0907, 0.1418, 0.1708, 0.0710,\n",
            "           0.1123]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1679, 0.1871, 0.2503, 0.2174, 0.1773],\n",
            "          [0.1705, 0.2197, 0.2311, 0.2099, 0.1688],\n",
            "          [0.1908, 0.2459, 0.1665, 0.2104, 0.1865],\n",
            "          [0.1930, 0.2437, 0.1722, 0.2047, 0.1863],\n",
            "          [0.1728, 0.1869, 0.2409, 0.2167, 0.1827]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1025, 0.0910, 0.1201, 0.1390, 0.1098, 0.1270, 0.1105, 0.0931,\n",
            "           0.1070],\n",
            "          [0.1089, 0.0989, 0.1151, 0.1242, 0.1097, 0.1194, 0.1092, 0.1032,\n",
            "           0.1113],\n",
            "          [0.0895, 0.0891, 0.0922, 0.1742, 0.1421, 0.1100, 0.1224, 0.0772,\n",
            "           0.1034],\n",
            "          [0.1036, 0.0995, 0.0884, 0.1406, 0.1323, 0.1071, 0.1178, 0.0936,\n",
            "           0.1170],\n",
            "          [0.1021, 0.0911, 0.1176, 0.1403, 0.1113, 0.1263, 0.1114, 0.0922,\n",
            "           0.1077]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2818, 0.1105, 0.1438, 0.1627, 0.1296, 0.1716],\n",
            "          [0.2149, 0.1314, 0.1661, 0.1579, 0.1492, 0.1805],\n",
            "          [0.2569, 0.1282, 0.1485, 0.1724, 0.1406, 0.1535],\n",
            "          [0.2148, 0.1395, 0.1609, 0.1649, 0.1553, 0.1645],\n",
            "          [0.2944, 0.1021, 0.1404, 0.1607, 0.1156, 0.1867],\n",
            "          [0.1668, 0.1665, 0.1827, 0.1587, 0.1951, 0.1302]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0847, 0.0752, 0.1804, 0.1818, 0.1255, 0.1041, 0.0950, 0.0883,\n",
            "           0.0651],\n",
            "          [0.0541, 0.0790, 0.1746, 0.2265, 0.1414, 0.1032, 0.1200, 0.0546,\n",
            "           0.0466],\n",
            "          [0.1223, 0.0704, 0.1667, 0.1340, 0.0980, 0.1137, 0.0776, 0.1234,\n",
            "           0.0940],\n",
            "          [0.0972, 0.0696, 0.1880, 0.1662, 0.1110, 0.1104, 0.0851, 0.0999,\n",
            "           0.0726],\n",
            "          [0.0434, 0.1009, 0.1275, 0.2316, 0.1926, 0.0740, 0.1432, 0.0476,\n",
            "           0.0393],\n",
            "          [0.1778, 0.0297, 0.2192, 0.0740, 0.0325, 0.1619, 0.0331, 0.1530,\n",
            "           0.1188]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1841, 0.1811, 0.1422, 0.1736, 0.2251, 0.0940],\n",
            "          [0.1809, 0.1682, 0.1598, 0.1759, 0.1967, 0.1185],\n",
            "          [0.1866, 0.1775, 0.1423, 0.1735, 0.2419, 0.0782],\n",
            "          [0.1848, 0.1806, 0.1418, 0.1740, 0.2269, 0.0920],\n",
            "          [0.1788, 0.1800, 0.1492, 0.1712, 0.2088, 0.1119],\n",
            "          [0.1755, 0.1552, 0.1710, 0.1761, 0.1682, 0.1540]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0770, 0.1541, 0.1203, 0.1137, 0.1333, 0.0946, 0.1437, 0.0889,\n",
            "           0.0744],\n",
            "          [0.0770, 0.1500, 0.1292, 0.1135, 0.1262, 0.1003, 0.1419, 0.0881,\n",
            "           0.0738],\n",
            "          [0.0834, 0.1509, 0.1215, 0.1090, 0.1296, 0.0942, 0.1361, 0.0969,\n",
            "           0.0784],\n",
            "          [0.0795, 0.1532, 0.1196, 0.1116, 0.1317, 0.0949, 0.1414, 0.0915,\n",
            "           0.0766],\n",
            "          [0.0685, 0.1553, 0.1220, 0.1229, 0.1400, 0.0933, 0.1519, 0.0791,\n",
            "           0.0670],\n",
            "          [0.1197, 0.1305, 0.1043, 0.0863, 0.1054, 0.1001, 0.1086, 0.1301,\n",
            "           0.1151]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1790, 0.1484, 0.1886, 0.1803, 0.1670, 0.1367],\n",
            "          [0.1807, 0.1483, 0.1886, 0.1812, 0.1721, 0.1291],\n",
            "          [0.1783, 0.1547, 0.1770, 0.1777, 0.1759, 0.1364],\n",
            "          [0.1789, 0.1496, 0.1868, 0.1800, 0.1674, 0.1373],\n",
            "          [0.1787, 0.1435, 0.1965, 0.1806, 0.1655, 0.1351],\n",
            "          [0.1766, 0.1609, 0.1758, 0.1776, 0.1615, 0.1478]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0797, 0.1653, 0.1013, 0.1007, 0.1239, 0.1016, 0.1527, 0.0870,\n",
            "           0.0877],\n",
            "          [0.0793, 0.1866, 0.0806, 0.0887, 0.1267, 0.0941, 0.1622, 0.0865,\n",
            "           0.0952],\n",
            "          [0.0777, 0.1883, 0.0927, 0.0923, 0.1368, 0.0838, 0.1546, 0.0925,\n",
            "           0.0813],\n",
            "          [0.0788, 0.1691, 0.0998, 0.0997, 0.1257, 0.0993, 0.1542, 0.0869,\n",
            "           0.0865],\n",
            "          [0.0849, 0.1444, 0.1081, 0.1063, 0.1134, 0.1163, 0.1445, 0.0867,\n",
            "           0.0953],\n",
            "          [0.0700, 0.1904, 0.0780, 0.0935, 0.1276, 0.0987, 0.1776, 0.0737,\n",
            "           0.0905]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1653, 0.1591, 0.1779, 0.1675, 0.1550, 0.1753],\n",
            "          [0.1651, 0.1581, 0.1810, 0.1678, 0.1525, 0.1755],\n",
            "          [0.1655, 0.1580, 0.1771, 0.1677, 0.1552, 0.1765],\n",
            "          [0.1652, 0.1590, 0.1779, 0.1675, 0.1549, 0.1755],\n",
            "          [0.1654, 0.1596, 0.1778, 0.1675, 0.1554, 0.1743],\n",
            "          [0.1644, 0.1587, 0.1828, 0.1674, 0.1508, 0.1758]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0639, 0.2021, 0.0682, 0.1053, 0.2005, 0.0526, 0.1600, 0.0838,\n",
            "           0.0637],\n",
            "          [0.0678, 0.1899, 0.0785, 0.1095, 0.1943, 0.0555, 0.1515, 0.0894,\n",
            "           0.0636],\n",
            "          [0.0650, 0.1999, 0.0705, 0.1044, 0.1836, 0.0609, 0.1656, 0.0810,\n",
            "           0.0690],\n",
            "          [0.0634, 0.2036, 0.0678, 0.1046, 0.1964, 0.0544, 0.1631, 0.0819,\n",
            "           0.0648],\n",
            "          [0.0673, 0.1917, 0.0710, 0.1090, 0.2194, 0.0448, 0.1435, 0.0943,\n",
            "           0.0590],\n",
            "          [0.0563, 0.2176, 0.0634, 0.0953, 0.1536, 0.0777, 0.1981, 0.0627,\n",
            "           0.0751]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1669, 0.1667, 0.1626, 0.1661, 0.1716, 0.1661],\n",
            "          [0.1669, 0.1661, 0.1622, 0.1661, 0.1714, 0.1673],\n",
            "          [0.1670, 0.1668, 0.1611, 0.1660, 0.1731, 0.1659],\n",
            "          [0.1669, 0.1666, 0.1625, 0.1661, 0.1718, 0.1660],\n",
            "          [0.1668, 0.1670, 0.1628, 0.1661, 0.1708, 0.1664],\n",
            "          [0.1669, 0.1649, 0.1640, 0.1663, 0.1715, 0.1662]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0753, 0.1671, 0.0823, 0.0845, 0.0909, 0.1437, 0.1747, 0.0681,\n",
            "           0.1136],\n",
            "          [0.0723, 0.1712, 0.0822, 0.0836, 0.0900, 0.1449, 0.1797, 0.0654,\n",
            "           0.1107],\n",
            "          [0.0690, 0.1725, 0.0778, 0.0842, 0.0897, 0.1479, 0.1868, 0.0608,\n",
            "           0.1113],\n",
            "          [0.0754, 0.1667, 0.0821, 0.0847, 0.0911, 0.1436, 0.1746, 0.0680,\n",
            "           0.1138],\n",
            "          [0.0745, 0.1694, 0.0830, 0.0833, 0.0900, 0.1441, 0.1759, 0.0676,\n",
            "           0.1122],\n",
            "          [0.0934, 0.1455, 0.0901, 0.0897, 0.0969, 0.1309, 0.1450, 0.0878,\n",
            "           0.1207]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1650, 0.1704, 0.1562, 0.1633, 0.1763, 0.1688],\n",
            "          [0.1651, 0.1712, 0.1567, 0.1634, 0.1763, 0.1672],\n",
            "          [0.1654, 0.1697, 0.1575, 0.1638, 0.1759, 0.1677],\n",
            "          [0.1651, 0.1702, 0.1565, 0.1635, 0.1762, 0.1685],\n",
            "          [0.1646, 0.1712, 0.1545, 0.1628, 0.1764, 0.1705],\n",
            "          [0.1659, 0.1690, 0.1598, 0.1645, 0.1758, 0.1651]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0999, 0.0897, 0.1097, 0.1491, 0.1186, 0.1225, 0.1136, 0.0887,\n",
            "           0.1083],\n",
            "          [0.1003, 0.0901, 0.1091, 0.1480, 0.1183, 0.1226, 0.1137, 0.0890,\n",
            "           0.1090],\n",
            "          [0.1004, 0.0901, 0.1039, 0.1503, 0.1221, 0.1197, 0.1144, 0.0885,\n",
            "           0.1107],\n",
            "          [0.0998, 0.0896, 0.1085, 0.1500, 0.1195, 0.1219, 0.1138, 0.0883,\n",
            "           0.1085],\n",
            "          [0.1009, 0.0903, 0.1164, 0.1438, 0.1133, 0.1256, 0.1120, 0.0907,\n",
            "           0.1070],\n",
            "          [0.0958, 0.0881, 0.1019, 0.1613, 0.1280, 0.1179, 0.1167, 0.0834,\n",
            "           0.1069]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.2286, 0.0897, 0.1167, 0.1320, 0.1052, 0.1260, 0.2018],\n",
            "          [0.1776, 0.1086, 0.1373, 0.1306, 0.1233, 0.1266, 0.1961],\n",
            "          [0.2137, 0.1066, 0.1235, 0.1434, 0.1169, 0.1378, 0.1581],\n",
            "          [0.1803, 0.1171, 0.1350, 0.1384, 0.1304, 0.1363, 0.1625],\n",
            "          [0.2330, 0.0808, 0.1111, 0.1272, 0.0915, 0.1176, 0.2388],\n",
            "          [0.1895, 0.1037, 0.1314, 0.1313, 0.1186, 0.1270, 0.1985],\n",
            "          [0.1564, 0.1262, 0.1671, 0.1266, 0.1679, 0.1286, 0.1273]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0830, 0.0769, 0.1771, 0.1838, 0.1297, 0.1015, 0.0968, 0.0872,\n",
            "           0.0639],\n",
            "          [0.0509, 0.0829, 0.1655, 0.2313, 0.1524, 0.0956, 0.1247, 0.0525,\n",
            "           0.0440],\n",
            "          [0.1176, 0.0736, 0.1635, 0.1391, 0.1051, 0.1092, 0.0811, 0.1203,\n",
            "           0.0905],\n",
            "          [0.0942, 0.0718, 0.1845, 0.1701, 0.1165, 0.1069, 0.0877, 0.0977,\n",
            "           0.0705],\n",
            "          [0.0438, 0.1036, 0.1233, 0.2283, 0.1976, 0.0714, 0.1439, 0.0485,\n",
            "           0.0395],\n",
            "          [0.0656, 0.0791, 0.1765, 0.2098, 0.1429, 0.0969, 0.1082, 0.0691,\n",
            "           0.0520],\n",
            "          [0.1545, 0.0335, 0.2303, 0.0895, 0.0379, 0.1727, 0.0407, 0.1313,\n",
            "           0.1096]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1519, 0.1578, 0.1205, 0.1448, 0.1861, 0.1651, 0.0738],\n",
            "          [0.1515, 0.1488, 0.1339, 0.1477, 0.1676, 0.1567, 0.0936],\n",
            "          [0.1529, 0.1571, 0.1193, 0.1438, 0.2010, 0.1668, 0.0591],\n",
            "          [0.1522, 0.1578, 0.1199, 0.1449, 0.1875, 0.1658, 0.0720],\n",
            "          [0.1488, 0.1566, 0.1259, 0.1435, 0.1748, 0.1591, 0.0913],\n",
            "          [0.1510, 0.1555, 0.1245, 0.1456, 0.1754, 0.1617, 0.0862],\n",
            "          [0.1502, 0.1306, 0.1555, 0.1521, 0.1404, 0.1433, 0.1280]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0759, 0.1547, 0.1198, 0.1148, 0.1349, 0.0939, 0.1449, 0.0876,\n",
            "           0.0735],\n",
            "          [0.0741, 0.1520, 0.1272, 0.1164, 0.1303, 0.0983, 0.1454, 0.0850,\n",
            "           0.0714],\n",
            "          [0.0810, 0.1524, 0.1211, 0.1109, 0.1321, 0.0933, 0.1385, 0.0944,\n",
            "           0.0765],\n",
            "          [0.0779, 0.1542, 0.1191, 0.1131, 0.1336, 0.0941, 0.1430, 0.0898,\n",
            "           0.0752],\n",
            "          [0.0677, 0.1559, 0.1202, 0.1242, 0.1424, 0.0920, 0.1530, 0.0782,\n",
            "           0.0664],\n",
            "          [0.0740, 0.1546, 0.1203, 0.1166, 0.1350, 0.0950, 0.1471, 0.0850,\n",
            "           0.0724],\n",
            "          [0.1197, 0.1286, 0.1093, 0.0860, 0.1024, 0.1026, 0.1073, 0.1304,\n",
            "           0.1136]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1535, 0.1304, 0.1637, 0.1547, 0.1442, 0.1435, 0.1100],\n",
            "          [0.1546, 0.1298, 0.1654, 0.1554, 0.1472, 0.1439, 0.1036],\n",
            "          [0.1522, 0.1351, 0.1540, 0.1521, 0.1506, 0.1468, 0.1091],\n",
            "          [0.1533, 0.1312, 0.1623, 0.1544, 0.1442, 0.1439, 0.1107],\n",
            "          [0.1535, 0.1267, 0.1710, 0.1552, 0.1435, 0.1405, 0.1097],\n",
            "          [0.1540, 0.1286, 0.1678, 0.1556, 0.1421, 0.1422, 0.1096],\n",
            "          [0.1513, 0.1410, 0.1484, 0.1516, 0.1419, 0.1484, 0.1175]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0800, 0.1630, 0.1033, 0.1017, 0.1234, 0.1024, 0.1515, 0.0873,\n",
            "           0.0874],\n",
            "          [0.0807, 0.1765, 0.0870, 0.0928, 0.1240, 0.0989, 0.1582, 0.0869,\n",
            "           0.0950],\n",
            "          [0.0785, 0.1831, 0.0963, 0.0943, 0.1354, 0.0857, 0.1524, 0.0930,\n",
            "           0.0812],\n",
            "          [0.0792, 0.1659, 0.1021, 0.1011, 0.1248, 0.1007, 0.1527, 0.0870,\n",
            "           0.0864],\n",
            "          [0.0854, 0.1381, 0.1137, 0.1095, 0.1113, 0.1198, 0.1414, 0.0864,\n",
            "           0.0945],\n",
            "          [0.0806, 0.1574, 0.1022, 0.1030, 0.1186, 0.1096, 0.1524, 0.0845,\n",
            "           0.0917],\n",
            "          [0.0693, 0.2068, 0.0695, 0.0861, 0.1323, 0.0894, 0.1807, 0.0753,\n",
            "           0.0906]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1427, 0.1367, 0.1526, 0.1443, 0.1341, 0.1382, 0.1515],\n",
            "          [0.1427, 0.1360, 0.1548, 0.1446, 0.1324, 0.1373, 0.1522],\n",
            "          [0.1429, 0.1361, 0.1519, 0.1445, 0.1346, 0.1386, 0.1514],\n",
            "          [0.1427, 0.1366, 0.1526, 0.1443, 0.1341, 0.1382, 0.1516],\n",
            "          [0.1427, 0.1372, 0.1522, 0.1442, 0.1346, 0.1384, 0.1506],\n",
            "          [0.1426, 0.1367, 0.1533, 0.1443, 0.1335, 0.1379, 0.1517],\n",
            "          [0.1423, 0.1351, 0.1580, 0.1446, 0.1295, 0.1357, 0.1549]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0640, 0.2020, 0.0678, 0.1053, 0.2021, 0.0518, 0.1592, 0.0842,\n",
            "           0.0635],\n",
            "          [0.0674, 0.1911, 0.0762, 0.1093, 0.2007, 0.0525, 0.1500, 0.0903,\n",
            "           0.0624],\n",
            "          [0.0652, 0.1999, 0.0698, 0.1047, 0.1876, 0.0588, 0.1637, 0.0821,\n",
            "           0.0681],\n",
            "          [0.0635, 0.2035, 0.0674, 0.1047, 0.1987, 0.0533, 0.1619, 0.0826,\n",
            "           0.0644],\n",
            "          [0.0670, 0.1925, 0.0694, 0.1086, 0.2230, 0.0434, 0.1428, 0.0946,\n",
            "           0.0586],\n",
            "          [0.0644, 0.2001, 0.0688, 0.1063, 0.2068, 0.0498, 0.1555, 0.0863,\n",
            "           0.0619],\n",
            "          [0.0591, 0.2080, 0.0702, 0.0978, 0.1483, 0.0828, 0.1919, 0.0654,\n",
            "           0.0764]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1429, 0.1435, 0.1394, 0.1423, 0.1474, 0.1446, 0.1400],\n",
            "          [0.1429, 0.1432, 0.1393, 0.1423, 0.1471, 0.1446, 0.1406],\n",
            "          [0.1429, 0.1437, 0.1382, 0.1422, 0.1486, 0.1452, 0.1392],\n",
            "          [0.1429, 0.1434, 0.1394, 0.1423, 0.1475, 0.1446, 0.1399],\n",
            "          [0.1428, 0.1437, 0.1396, 0.1423, 0.1465, 0.1444, 0.1407],\n",
            "          [0.1428, 0.1433, 0.1398, 0.1424, 0.1469, 0.1444, 0.1404],\n",
            "          [0.1430, 0.1422, 0.1399, 0.1425, 0.1482, 0.1445, 0.1396]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0752, 0.1672, 0.0822, 0.0844, 0.0908, 0.1438, 0.1749, 0.0679,\n",
            "           0.1135],\n",
            "          [0.0730, 0.1706, 0.0825, 0.0835, 0.0900, 0.1446, 0.1785, 0.0661,\n",
            "           0.1111],\n",
            "          [0.0690, 0.1728, 0.0778, 0.0840, 0.0895, 0.1480, 0.1869, 0.0608,\n",
            "           0.1112],\n",
            "          [0.0753, 0.1668, 0.0821, 0.0846, 0.0910, 0.1437, 0.1747, 0.0680,\n",
            "           0.1138],\n",
            "          [0.0749, 0.1689, 0.0832, 0.0833, 0.0900, 0.1439, 0.1752, 0.0681,\n",
            "           0.1125],\n",
            "          [0.0773, 0.1656, 0.0840, 0.0844, 0.0912, 0.1422, 0.1710, 0.0705,\n",
            "           0.1139],\n",
            "          [0.0866, 0.1524, 0.0877, 0.0891, 0.0959, 0.1350, 0.1552, 0.0803,\n",
            "           0.1178]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1408, 0.1462, 0.1333, 0.1395, 0.1511, 0.1459, 0.1433],\n",
            "          [0.1407, 0.1468, 0.1334, 0.1395, 0.1509, 0.1458, 0.1429],\n",
            "          [0.1410, 0.1458, 0.1343, 0.1399, 0.1508, 0.1456, 0.1425],\n",
            "          [0.1408, 0.1461, 0.1335, 0.1396, 0.1510, 0.1458, 0.1431],\n",
            "          [0.1403, 0.1467, 0.1317, 0.1390, 0.1511, 0.1462, 0.1450],\n",
            "          [0.1406, 0.1465, 0.1329, 0.1394, 0.1511, 0.1459, 0.1435],\n",
            "          [0.1418, 0.1453, 0.1373, 0.1408, 0.1505, 0.1450, 0.1393]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0999, 0.0897, 0.1101, 0.1489, 0.1183, 0.1226, 0.1135, 0.0888,\n",
            "           0.1081],\n",
            "          [0.1003, 0.0901, 0.1108, 0.1472, 0.1171, 0.1233, 0.1133, 0.0893,\n",
            "           0.1084],\n",
            "          [0.1006, 0.0901, 0.1049, 0.1497, 0.1213, 0.1202, 0.1141, 0.0888,\n",
            "           0.1104],\n",
            "          [0.0998, 0.0896, 0.1091, 0.1497, 0.1191, 0.1222, 0.1137, 0.0885,\n",
            "           0.1083],\n",
            "          [0.1010, 0.0903, 0.1174, 0.1434, 0.1127, 0.1259, 0.1118, 0.0909,\n",
            "           0.1066],\n",
            "          [0.0998, 0.0897, 0.1125, 0.1481, 0.1168, 0.1238, 0.1132, 0.0889,\n",
            "           0.1073],\n",
            "          [0.0962, 0.0886, 0.0992, 0.1610, 0.1294, 0.1168, 0.1171, 0.0835,\n",
            "           0.1083]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0871, 0.0456, 0.1022, 0.0632, 0.1169, 0.1226, 0.2159, 0.2465],\n",
            "          [0.4786, 0.0089, 0.0581, 0.0507, 0.0998, 0.0341, 0.0574, 0.2124],\n",
            "          [0.0155, 0.5514, 0.0655, 0.0851, 0.0670, 0.1160, 0.0351, 0.0644],\n",
            "          [0.0585, 0.2493, 0.1136, 0.1204, 0.1109, 0.1361, 0.0851, 0.1260],\n",
            "          [0.1862, 0.0246, 0.0679, 0.0494, 0.1307, 0.0766, 0.1009, 0.3636],\n",
            "          [0.1927, 0.0365, 0.0735, 0.0614, 0.1354, 0.0789, 0.0866, 0.3350],\n",
            "          [0.0175, 0.6812, 0.0491, 0.1045, 0.0399, 0.0774, 0.0210, 0.0094],\n",
            "          [0.1895, 0.1349, 0.0654, 0.0866, 0.1721, 0.1153, 0.0442, 0.1921]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0554, 0.1051, 0.1244, 0.2075, 0.1932, 0.0718, 0.1322, 0.0627,\n",
            "           0.0476],\n",
            "          [0.1081, 0.1300, 0.0772, 0.1051, 0.1297, 0.0953, 0.1248, 0.1069,\n",
            "           0.1230],\n",
            "          [0.1503, 0.0374, 0.2075, 0.0859, 0.0371, 0.1922, 0.0465, 0.1213,\n",
            "           0.1218],\n",
            "          [0.1104, 0.0920, 0.1195, 0.1173, 0.0913, 0.1433, 0.1077, 0.0973,\n",
            "           0.1211],\n",
            "          [0.0436, 0.1031, 0.1240, 0.2292, 0.1973, 0.0715, 0.1437, 0.0483,\n",
            "           0.0393],\n",
            "          [0.0682, 0.0834, 0.1705, 0.1930, 0.1280, 0.1135, 0.1156, 0.0679,\n",
            "           0.0600],\n",
            "          [0.1915, 0.0270, 0.2142, 0.0636, 0.0280, 0.1583, 0.0286, 0.1650,\n",
            "           0.1237],\n",
            "          [0.1673, 0.0377, 0.1976, 0.0819, 0.0399, 0.1651, 0.0426, 0.1431,\n",
            "           0.1248]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1886, 0.0952, 0.0746, 0.0817, 0.1963, 0.1941, 0.0895, 0.0800],\n",
            "          [0.1378, 0.2164, 0.0823, 0.1540, 0.1317, 0.1214, 0.0720, 0.0846],\n",
            "          [0.0835, 0.1683, 0.1466, 0.1615, 0.0745, 0.0639, 0.1435, 0.1582],\n",
            "          [0.1263, 0.2279, 0.0903, 0.1631, 0.1143, 0.0931, 0.0837, 0.1013],\n",
            "          [0.1754, 0.1035, 0.0852, 0.0915, 0.1795, 0.1741, 0.0994, 0.0915],\n",
            "          [0.0588, 0.1134, 0.2061, 0.1509, 0.0587, 0.0701, 0.1705, 0.1715],\n",
            "          [0.0750, 0.1025, 0.1837, 0.1276, 0.0730, 0.0799, 0.1875, 0.1707],\n",
            "          [0.1686, 0.1408, 0.0865, 0.1098, 0.1563, 0.1240, 0.1073, 0.1066]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0684, 0.1573, 0.1169, 0.1235, 0.1451, 0.0897, 0.1527, 0.0793,\n",
            "           0.0670],\n",
            "          [0.0970, 0.1359, 0.1154, 0.1101, 0.1327, 0.0891, 0.1207, 0.1116,\n",
            "           0.0875],\n",
            "          [0.1492, 0.1074, 0.0977, 0.0740, 0.0872, 0.1025, 0.0863, 0.1550,\n",
            "           0.1407],\n",
            "          [0.1120, 0.1262, 0.1217, 0.0970, 0.1119, 0.0978, 0.1080, 0.1262,\n",
            "           0.0992],\n",
            "          [0.0678, 0.1557, 0.1205, 0.1239, 0.1419, 0.0924, 0.1529, 0.0783,\n",
            "           0.0666],\n",
            "          [0.0931, 0.1336, 0.0917, 0.1173, 0.1343, 0.0987, 0.1346, 0.0946,\n",
            "           0.1021],\n",
            "          [0.1503, 0.1123, 0.0744, 0.0742, 0.0976, 0.0931, 0.0909, 0.1508,\n",
            "           0.1563],\n",
            "          [0.1151, 0.1311, 0.1135, 0.0892, 0.1064, 0.1005, 0.1096, 0.1277,\n",
            "           0.1069]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1705, 0.1645, 0.0805, 0.1284, 0.1536, 0.0632, 0.0999, 0.1393],\n",
            "          [0.1005, 0.1135, 0.1045, 0.0926, 0.1055, 0.2865, 0.1248, 0.0721],\n",
            "          [0.1715, 0.0664, 0.1142, 0.0822, 0.1774, 0.1123, 0.1245, 0.1515],\n",
            "          [0.1301, 0.0809, 0.0928, 0.0703, 0.1382, 0.2835, 0.1250, 0.0792],\n",
            "          [0.1764, 0.1663, 0.0764, 0.1268, 0.1581, 0.0607, 0.0966, 0.1387],\n",
            "          [0.1188, 0.1741, 0.1144, 0.1895, 0.1088, 0.0324, 0.0857, 0.1762],\n",
            "          [0.1450, 0.0854, 0.1372, 0.1214, 0.1425, 0.0497, 0.1149, 0.2039],\n",
            "          [0.1901, 0.0805, 0.0922, 0.0812, 0.1877, 0.1066, 0.1205, 0.1411]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0904, 0.1086, 0.1427, 0.1234, 0.1015, 0.1322, 0.1214, 0.0889,\n",
            "           0.0909],\n",
            "          [0.0956, 0.1686, 0.0767, 0.0922, 0.1458, 0.0757, 0.1355, 0.1104,\n",
            "           0.0996],\n",
            "          [0.0650, 0.2205, 0.0517, 0.0785, 0.1295, 0.0894, 0.1980, 0.0658,\n",
            "           0.1015],\n",
            "          [0.0746, 0.2600, 0.0431, 0.0610, 0.1618, 0.0500, 0.1628, 0.0970,\n",
            "           0.0897],\n",
            "          [0.0910, 0.1169, 0.1289, 0.1174, 0.1034, 0.1301, 0.1274, 0.0890,\n",
            "           0.0961],\n",
            "          [0.0771, 0.0799, 0.0986, 0.1316, 0.0699, 0.2249, 0.1379, 0.0505,\n",
            "           0.1295],\n",
            "          [0.0689, 0.1226, 0.0998, 0.1247, 0.0964, 0.1631, 0.1665, 0.0565,\n",
            "           0.1015],\n",
            "          [0.0711, 0.2152, 0.0723, 0.0832, 0.1410, 0.0779, 0.1716, 0.0838,\n",
            "           0.0838]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1157, 0.1511, 0.1253, 0.1407, 0.1135, 0.1049, 0.1217, 0.1271],\n",
            "          [0.1256, 0.1319, 0.1243, 0.1163, 0.1213, 0.1083, 0.1386, 0.1337],\n",
            "          [0.1027, 0.1780, 0.1280, 0.1915, 0.0989, 0.0580, 0.0955, 0.1473],\n",
            "          [0.1187, 0.1522, 0.1265, 0.1381, 0.1128, 0.0798, 0.1262, 0.1457],\n",
            "          [0.1152, 0.1533, 0.1257, 0.1448, 0.1127, 0.0996, 0.1193, 0.1294],\n",
            "          [0.1101, 0.1601, 0.1283, 0.1866, 0.1084, 0.0679, 0.0940, 0.1448],\n",
            "          [0.1049, 0.1697, 0.1289, 0.1864, 0.1032, 0.0725, 0.0970, 0.1374],\n",
            "          [0.1091, 0.1676, 0.1273, 0.1592, 0.1056, 0.0828, 0.1137, 0.1347]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0641, 0.2003, 0.0607, 0.1052, 0.2381, 0.0383, 0.1440, 0.0925,\n",
            "           0.0567],\n",
            "          [0.1167, 0.1229, 0.0885, 0.1052, 0.1332, 0.0856, 0.1097, 0.1247,\n",
            "           0.1136],\n",
            "          [0.0523, 0.1862, 0.0700, 0.0795, 0.0795, 0.1665, 0.2219, 0.0431,\n",
            "           0.1012],\n",
            "          [0.1075, 0.1037, 0.1301, 0.1020, 0.0840, 0.1465, 0.1112, 0.1000,\n",
            "           0.1149],\n",
            "          [0.0654, 0.1959, 0.0645, 0.1070, 0.2358, 0.0390, 0.1411, 0.0948,\n",
            "           0.0563],\n",
            "          [0.0703, 0.1919, 0.0625, 0.1052, 0.2287, 0.0410, 0.1392, 0.0988,\n",
            "           0.0623],\n",
            "          [0.0453, 0.2523, 0.0417, 0.0799, 0.1460, 0.0748, 0.2351, 0.0469,\n",
            "           0.0779],\n",
            "          [0.0560, 0.2125, 0.0659, 0.0927, 0.1338, 0.0937, 0.2059, 0.0582,\n",
            "           0.0813]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1205, 0.1259, 0.1261, 0.1195, 0.1211, 0.1417, 0.1300, 0.1152],\n",
            "          [0.1353, 0.0523, 0.1328, 0.0601, 0.1406, 0.1985, 0.1689, 0.1114],\n",
            "          [0.0975, 0.1831, 0.1182, 0.1275, 0.0964, 0.1501, 0.1344, 0.0928],\n",
            "          [0.1103, 0.0774, 0.1308, 0.0642, 0.1129, 0.2291, 0.1859, 0.0895],\n",
            "          [0.1200, 0.1260, 0.1267, 0.1196, 0.1206, 0.1410, 0.1306, 0.1155],\n",
            "          [0.1279, 0.1208, 0.1273, 0.1339, 0.1276, 0.1084, 0.1177, 0.1364],\n",
            "          [0.1094, 0.1858, 0.1119, 0.1617, 0.1081, 0.1077, 0.1031, 0.1124],\n",
            "          [0.1050, 0.1582, 0.1200, 0.1196, 0.1050, 0.1613, 0.1353, 0.0956]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0772, 0.1663, 0.0837, 0.0835, 0.0903, 0.1429, 0.1713, 0.0704,\n",
            "           0.1143],\n",
            "          [0.0334, 0.2030, 0.0489, 0.0752, 0.0737, 0.1711, 0.2827, 0.0246,\n",
            "           0.0874],\n",
            "          [0.1366, 0.1006, 0.1095, 0.0971, 0.1056, 0.0972, 0.0891, 0.1439,\n",
            "           0.1204],\n",
            "          [0.0427, 0.1926, 0.0600, 0.0838, 0.0835, 0.1618, 0.2494, 0.0338,\n",
            "           0.0925],\n",
            "          [0.0778, 0.1661, 0.0849, 0.0834, 0.0905, 0.1422, 0.1700, 0.0713,\n",
            "           0.1138],\n",
            "          [0.1412, 0.1037, 0.1160, 0.0863, 0.0974, 0.0965, 0.0852, 0.1547,\n",
            "           0.1189],\n",
            "          [0.1768, 0.0747, 0.1118, 0.0842, 0.0954, 0.0762, 0.0580, 0.2001,\n",
            "           0.1227],\n",
            "          [0.0876, 0.1498, 0.0872, 0.0907, 0.0970, 0.1343, 0.1536, 0.0808,\n",
            "           0.1189]]]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.0936, 0.0973, 0.1467, 0.1001, 0.0974, 0.2352, 0.1408, 0.0890],\n",
            "          [0.0932, 0.0953, 0.1492, 0.0951, 0.0955, 0.2167, 0.1618, 0.0932],\n",
            "          [0.1211, 0.1714, 0.1028, 0.1404, 0.1207, 0.1351, 0.1008, 0.1076],\n",
            "          [0.1154, 0.1441, 0.1175, 0.1255, 0.1155, 0.1515, 0.1225, 0.1081],\n",
            "          [0.0945, 0.0971, 0.1468, 0.1005, 0.0984, 0.2331, 0.1399, 0.0898],\n",
            "          [0.0953, 0.0868, 0.1539, 0.0946, 0.0992, 0.2252, 0.1512, 0.0937],\n",
            "          [0.0997, 0.1267, 0.1296, 0.1149, 0.1021, 0.2079, 0.1274, 0.0917],\n",
            "          [0.1080, 0.1397, 0.1214, 0.1239, 0.1098, 0.1811, 0.1180, 0.0981]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[[[0.1026, 0.0909, 0.1202, 0.1390, 0.1098, 0.1269, 0.1104, 0.0932,\n",
            "           0.1070],\n",
            "          [0.1135, 0.1000, 0.1217, 0.1134, 0.1008, 0.1229, 0.1053, 0.1095,\n",
            "           0.1129],\n",
            "          [0.0897, 0.0897, 0.0913, 0.1733, 0.1427, 0.1094, 0.1227, 0.0774,\n",
            "           0.1038],\n",
            "          [0.1087, 0.1002, 0.0924, 0.1311, 0.1240, 0.1100, 0.1141, 0.0993,\n",
            "           0.1202],\n",
            "          [0.1024, 0.0910, 0.1211, 0.1387, 0.1093, 0.1274, 0.1103, 0.0932,\n",
            "           0.1066],\n",
            "          [0.0983, 0.0923, 0.1583, 0.1266, 0.0938, 0.1371, 0.1059, 0.0952,\n",
            "           0.0924],\n",
            "          [0.0896, 0.0855, 0.1216, 0.1671, 0.1216, 0.1245, 0.1158, 0.0795,\n",
            "           0.0947],\n",
            "          [0.0972, 0.0894, 0.0954, 0.1598, 0.1315, 0.1145, 0.1174, 0.0843,\n",
            "           0.1104]]]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([1, 8, 10])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Transformer_0.5_tf.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}