{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2yAW3X4l3yit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1e1e07-461d-448c-ec3f-c06629c0e795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n",
            "Collecting torchvision==0.10.0\n",
            "  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.6)\n",
            "Collecting torch\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchvision-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.0\n",
            "    Uninstalling torchtext-0.13.0:\n",
            "      Successfully uninstalled torchtext-0.13.0\n",
            "Successfully installed torchtext-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision==0.10.0\n",
        "!pip install -U torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sf8kIKvdh1V8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vz_4T8WU53Oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3cbb3b-e3cd-4ebf-82eb-e7d6dbce289c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 569 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.4.0) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en \n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U5h2gakV53St"
      },
      "outputs": [],
      "source": [
        "spacy_ger = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d7C73-OxYTCJ"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YWzy49BA58et"
      },
      "outputs": [],
      "source": [
        "def tokenize_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g-U6dWUh58iX"
      },
      "outputs": [],
      "source": [
        "German = Field(tokenize = tokenize_ger, init_token = '<sos>', eos_token = '<eos>', lower = True, batch_first = True)\n",
        "English = Field(tokenize = tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True, batch_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7DtZ05kB58mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7517a8-8ab9-4be7-e970-c3b834f85a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 421kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 114kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 108kB/s]\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (German, English))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCoNH_176Fx5",
        "outputId": "e91f06d2-4742-4cf8-f9f5-772128dbafb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZkLnm8Dp6F05"
      },
      "outputs": [],
      "source": [
        "German.build_vocab(train_data, min_freq = 2)\n",
        "English.build_vocab(train_data, min_freq = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzRS3fNg6F5D",
        "outputId": "048324a8-c8cf-4965-90af-b8a38a7dd40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German vocabulary: 7853\n",
            "English vocabulary: 5893\n"
          ]
        }
      ],
      "source": [
        "print(f\"German vocabulary: {len(German.vocab)}\")\n",
        "print(f\"English vocabulary: {len(English.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-DNloii16Ukn"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), batch_size = BATCH_SIZE, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4w2iwCggb0pn"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        x = self.fc_2(x)        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zuNLGeial48E"
      },
      "outputs": [],
      "source": [
        "class SelfAtt(nn.Module):\n",
        "  def __init__(self, emb_size, heads,dropout):\n",
        "    super(SelfAtt,self).__init__()\n",
        "    self.emb_size = emb_size\n",
        "    self.heads = heads\n",
        "    self.head_dim = emb_size//heads\n",
        "    assert(self.head_dim*heads == self.emb_size), \"head_dim*heads != emb_size\"\n",
        "\n",
        "    self.query = nn.Linear(self.emb_size,self.emb_size)\n",
        "    self.key = nn.Linear(self.emb_size,self.emb_size)\n",
        "    self.value = nn.Linear(self.emb_size,self.emb_size)\n",
        "\n",
        "    self.fc_out = nn.Linear(self.head_dim*heads, self.emb_size)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,values,keys,query,mask=None):\n",
        "    N = query.shape[0]\n",
        "    values = self.value(values)\n",
        "    keys = self.key(keys)  \n",
        "    query1 = self.query(query) \n",
        "\n",
        "    values = values.view(N, -1, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    keys = keys.view(N, -1, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    query1 = query1.view(N, -1, self.heads, self.head_dim).permute(0, 2, 1, 3)   \n",
        "\n",
        "    #dot product of keys and query\n",
        "    energy = torch.matmul(query1, keys.permute(0, 1, 3, 2)) / self.scale\n",
        "    #print(energy.shape)\n",
        "\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "      #print(energy)\n",
        "    \n",
        "    attention = torch.softmax(energy, dim= -1)\n",
        "    #print(attention.shape)\n",
        "    #print(values.shape)\n",
        "    x = torch.matmul(self.dropout(attention), values)    \n",
        "    x = x.permute(0, 2, 1, 3).contiguous()\n",
        "    out = x.view(N, -1, self.emb_size)\n",
        "    \n",
        "    out =  self.fc_out(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9oeuJAMnuCk-"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,emb_size, heads, dropout, forward_expansion):\n",
        "    super(TransformerBlock,self).__init__()\n",
        "    self.att = SelfAtt(emb_size,heads,dropout)\n",
        "    self.norm1 = nn.LayerNorm(emb_size)\n",
        "    self.norm2 = nn.LayerNorm(emb_size)\n",
        "\n",
        "    self.feed_forward = PositionwiseFeedforwardLayer(emb_size, forward_expansion*emb_size, dropout)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, value, key, query):\n",
        "    att = self.att(value, key, query)\n",
        "    x = self.norm1(query + self.dropout(att))\n",
        "    forward = self.feed_forward(x)\n",
        "    out  = self.norm2(x + self.dropout(forward))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HEiexFCTxhqf"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, \n",
        "               src_vocab_size, \n",
        "               emb_size,\n",
        "               num_layers,\n",
        "               heads,\n",
        "               device,\n",
        "               forward_expansion,\n",
        "               dropout,\n",
        "               max_length,\n",
        "               ):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.emb_size = emb_size\n",
        "    self.device = device\n",
        "    self.word_embedding  = nn.Embedding(src_vocab_size,emb_size)\n",
        "    self.position_embedding = nn.Embedding(max_length, emb_size)\n",
        "    self.layers = nn.ModuleList(\n",
        "        [\n",
        "         TransformerBlock(\n",
        "             emb_size,\n",
        "             heads,\n",
        "             dropout = dropout,\n",
        "             forward_expansion = forward_expansion,\n",
        "         )\n",
        "         for _ in range(num_layers)\n",
        "        ]\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([emb_size])).to(device)\n",
        "  def forward(self,x):\n",
        "    N,seq_length = x.shape\n",
        "    positions = torch.arange(0, seq_length).unsqueeze(0).repeat(N, 1).to(self.device)\n",
        "    out = self.dropout(self.word_embedding(x)*self.scale + self.position_embedding(positions))\n",
        "    for layer in self.layers:\n",
        "      out  = layer(out,out,out)\n",
        "      \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-AD6srbm3eYj"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, emb_size, heads, forward_expansion, dropout, device):\n",
        "    super(DecoderBlock,self).__init__()\n",
        "    self.attention = SelfAtt(emb_size,heads,dropout)\n",
        "    self.norm1 = nn.LayerNorm(emb_size)\n",
        "    self.norm = nn.LayerNorm(emb_size)\n",
        "    self.transformer_block = TransformerBlock(emb_size, heads, dropout, forward_expansion)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, value, key):\n",
        "    attention = self.attention(x,x,x)\n",
        "    query = self.norm1(self.dropout(attention) + x)\n",
        "    out  = self.transformer_block(value, key, query)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uZFojgCL5fQg"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        trg_vocab_size,\n",
        "        embed_size,\n",
        "        num_layers,\n",
        "        heads,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        device,\n",
        "        max_length,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([embed_size])).to(device)\n",
        "\n",
        "    def forward(self, x, enc_out):\n",
        "        N, seq_length = x.shape\n",
        "        positions = torch.arange(0, seq_length).unsqueeze(0).repeat(N, 1).to(self.device)\n",
        "        x = self.dropout((self.word_embedding(x)*self.scale) + self.position_embedding(positions))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out, enc_out)\n",
        "        out = self.fc_out(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DvUN9vRyJPtK"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        embed_size=5,\n",
        "        num_layers=6,\n",
        "        forward_expansion=4,\n",
        "        heads=1,\n",
        "        dropout=0,\n",
        "        device=\"cpu\",\n",
        "        max_length=10,\n",
        "        src_pad_idx = 0,\n",
        "        trg_pad_idx = 0,\n",
        "        teacher_force = 0.5,\n",
        "    ):\n",
        "\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            src_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            device,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            max_length,\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            trg_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            device,\n",
        "            max_length,\n",
        "        )\n",
        "\n",
        "        self.device = device\n",
        "        self.trg_vocab_size = trg_vocab_size\n",
        "        self.teacher_force = teacher_force\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        enc_src = self.encoder(src)\n",
        "        outputs = torch.zeros((trg.shape[0],trg.shape[1],self.trg_vocab_size)).to(self.device)\n",
        "        trg_dec = trg[:,0:1]\n",
        "        for i in range(trg.shape[1]):\n",
        "            out = self.decoder(trg_dec, enc_src)\n",
        "            outputs[:,i,:] = out[:,-1,:]\n",
        "            trg_dec = torch.argmax(outputs[:,0:i+2,:],dim = 2) if random.random() < self.teacher_force else trg[:,0:i+2]\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "J9kiCLVt8aKf"
      },
      "outputs": [],
      "source": [
        "src_vocab_size = len(German.vocab)\n",
        "trg_vocab_size = len(English.vocab)\n",
        "embed_size= 256\n",
        "num_layers= 3\n",
        "forward_expansion= 2\n",
        "heads=8\n",
        "dropout= 0.1\n",
        "max_length= 100\n",
        "teacher_force = 0.5\n",
        "TRG_PAD_IDX = English.vocab.stoi[English.pad_token]\n",
        "SRC_PAD_IDX = German.vocab.stoi[German.pad_token]\n",
        "\n",
        "model  = Transformer( src_vocab_size, trg_vocab_size, embed_size, num_layers, forward_expansion, heads, dropout, device, max_length, SRC_PAD_IDX, TRG_PAD_IDX, teacher_force).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgxWiE2v8HqY",
        "outputId": "bc82c04e-b211-4db8-8bc9-811ecb87d0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,039,877 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fayTdOWP8hEz"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "model.apply(initialize_weights);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "s2iNNbvh8hL9"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NZdLFmU78xEo"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BkFvTc_N8xHO"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #print(trg.shape)\n",
        "        output = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qZ3EHT2p8xJW"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "            trg1 = trg\n",
        "\n",
        "            output = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), output, trg1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UtHIxBu_9BaC"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "P1LmC7IS9Bcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd517a24-984b-48ff-ff19-d44ff2e6a0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 4m 26s\n",
            "\tTrain Loss: 4.230 | Train PPL:  68.705\n",
            "\t Val. Loss: 3.345 |  Val. PPL:  28.369\n",
            "Epoch: 02 | Time: 4m 19s\n",
            "\tTrain Loss: 3.202 | Train PPL:  24.579\n",
            "\t Val. Loss: 2.765 |  Val. PPL:  15.876\n",
            "Epoch: 03 | Time: 4m 19s\n",
            "\tTrain Loss: 2.742 | Train PPL:  15.518\n",
            "\t Val. Loss: 2.496 |  Val. PPL:  12.139\n",
            "Epoch: 04 | Time: 4m 19s\n",
            "\tTrain Loss: 2.454 | Train PPL:  11.639\n",
            "\t Val. Loss: 2.422 |  Val. PPL:  11.270\n",
            "Epoch: 05 | Time: 4m 20s\n",
            "\tTrain Loss: 2.246 | Train PPL:   9.448\n",
            "\t Val. Loss: 2.347 |  Val. PPL:  10.457\n",
            "Epoch: 06 | Time: 4m 22s\n",
            "\tTrain Loss: 2.098 | Train PPL:   8.151\n",
            "\t Val. Loss: 2.221 |  Val. PPL:   9.219\n",
            "Epoch: 07 | Time: 4m 20s\n",
            "\tTrain Loss: 1.974 | Train PPL:   7.201\n",
            "\t Val. Loss: 2.230 |  Val. PPL:   9.300\n",
            "Epoch: 08 | Time: 4m 17s\n",
            "\tTrain Loss: 1.877 | Train PPL:   6.534\n",
            "\t Val. Loss: 2.138 |  Val. PPL:   8.484\n",
            "Epoch: 09 | Time: 4m 15s\n",
            "\tTrain Loss: 1.792 | Train PPL:   6.000\n",
            "\t Val. Loss: 2.219 |  Val. PPL:   9.199\n",
            "Epoch: 10 | Time: 4m 17s\n",
            "\tTrain Loss: 1.701 | Train PPL:   5.481\n",
            "\t Val. Loss: 2.273 |  Val. PPL:   9.706\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss, output, trg = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tranformer_1.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0yigifH8GFn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e717225-9d68-4848-cc84-2cc26f9ec906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.238 | Test PPL:   9.378 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tranformer_1.pt'))\n",
        "\n",
        "test_loss, output, trg = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    model.eval()   \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    #src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        #trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(trg_tensor, enc_src)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens"
      ],
      "metadata": {
        "id": "qel0K6dyE-Q7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 10\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "metadata": {
        "id": "mmjoI8bYE-Tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cf9c19-5d63-4790-dc38-1a62f3b25eae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['eine', 'ballettklasse', 'mit', 'fünf', 'mädchen', ',', 'die', 'nacheinander', 'springen', '.']\n",
            "trg = ['a', 'ballet', 'class', 'of', 'five', 'girls', 'jumping', 'in', 'sequence', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translate_sentence(src, German, English, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "metadata": {
        "id": "Z8RYTrZME-WR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4c09d5-1263-458a-e1f3-1e373d9066ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['<sos>', 'a', 'ballet', 'of', 'five', 'girls', 'jumping', 'in', 'sequence', '.', '<eos>']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Translation_Transformer_no_mask.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}