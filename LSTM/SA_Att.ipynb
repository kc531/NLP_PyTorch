{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2rEgNkgJxL7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfedd61e-ebe6-4fb1-e057-e5a6f709af8c"
      },
      "id": "2rEgNkgJxL7A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/SA"
      ],
      "metadata": {
        "id": "_k6xw17QxvnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26edef62-e42e-4920-9ea3-dfadd378e71b"
      },
      "id": "_k6xw17QxvnK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==4.2.0"
      ],
      "metadata": {
        "id": "43niaxtwxNg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749daf5d-2de0-40c0-b27a-e58547090c1a"
      },
      "id": "43niaxtwxNg4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.2.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4ecf10",
      "metadata": {
        "id": "5f4ecf10"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "import re\n",
        "import nltk\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "from LSTM import DLSTM, CustomLSTM\n",
        "from BILSTM import DBLSTM\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from w2v import w2v_prep\n",
        "from Attent import Att\n",
        "writer = SummaryWriter()\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531c7a85",
      "metadata": {
        "id": "531c7a85"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "df = pd.read_csv('data_imdb.csv')\n",
        "df = df.head(5000)\n",
        "review = df['review'].to_list()\n",
        "sentiment = df['sentiment'].to_list()\n",
        "y = [0] * len(sentiment)\n",
        "for i in range(len(sentiment)):\n",
        "    if sentiment[i] == 'positive':\n",
        "        y[i] = 1\n",
        "df1 = pd.DataFrame(data=np.array(y).T, columns=['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9bfa02",
      "metadata": {
        "id": "ac9bfa02"
      },
      "outputs": [],
      "source": [
        "ED = 50\n",
        "seq_len = 100\n",
        "w2v_model, review_text, vocab_len, X_train, X_val, X_test, Y_train, Y_val, Y_test = w2v_prep(df, df1, ED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec74769",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ec74769",
        "outputId": "3bf1c6af-c75b-4063-8228-a08cb8044cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12188\n"
          ]
        }
      ],
      "source": [
        "weights = torch.FloatTensor(w2v_model.wv.vectors)\n",
        "vocab = w2v_model.wv.key_to_index\n",
        "print(len(vocab))\n",
        "vocab[' '] = len(vocab) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2858fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a2858fd",
        "outputId": "8d6f6217-7540-4f71-eddd-231972803361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12189, 50])\n"
          ]
        }
      ],
      "source": [
        "weights = torch.cat((weights,torch.tensor(([ED*[0]]),dtype=float)),dim=0)\n",
        "print(weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c33e9d",
      "metadata": {
        "id": "28c33e9d"
      },
      "outputs": [],
      "source": [
        "def tockenize(vocab,seq_len,x_vec):\n",
        "    word_list = []  \n",
        "    \n",
        "    final_token = np.array([],dtype = int)  \n",
        "    count=0\n",
        "    \n",
        "    for sent in x_vec:\n",
        "        sent_len = len(sent)\n",
        "        tokens = [vocab[word] for word in sent if word in vocab.keys()]\n",
        "        \n",
        "        # CALCULATING TOKENS\n",
        "        if len(tokens) >= seq_len:\n",
        "            temp_vec = np.array(tokens[0:seq_len])\n",
        "        else:\n",
        "            temp_vec = np.array(tokens + (seq_len - len(tokens)) * [vocab[' ']])\n",
        "            \n",
        "        # STACKING   \n",
        "        if count==0:\n",
        "            final_token = np.hstack((final_token,temp_vec))\n",
        "            count+=1\n",
        "        else:\n",
        "            final_token = np.vstack((final_token,temp_vec))\n",
        "        \n",
        "    return final_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a00a14",
      "metadata": {
        "id": "57a00a14"
      },
      "outputs": [],
      "source": [
        "x_train = tockenize(vocab,seq_len,X_train)\n",
        "np.save('x_train',x_train)\n",
        "x_val = tockenize(vocab,seq_len,X_val)\n",
        "np.save('x_val',x_val)\n",
        "x_test = tockenize(vocab,seq_len,X_test)\n",
        "np.save('x_test',x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27a0ec7",
      "metadata": {
        "id": "f27a0ec7"
      },
      "outputs": [],
      "source": [
        "x_train = np.load('x_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "x_val = np.load('x_val.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329980fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "329980fb",
        "outputId": "de843ab4-0a9d-4329-e422-5480e434b9de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3500, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d6beb7",
      "metadata": {
        "id": "20d6beb7"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(np.array(Y_train)))\n",
        "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(np.array(Y_test)))\n",
        "valid_data = TensorDataset(torch.from_numpy(x_val), torch.from_numpy(np.array(Y_val)))\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c197dbf",
      "metadata": {
        "id": "9c197dbf"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, weights, output_dim, vocab_size, hidden_dim, embedding_dim, batch_size, seq_len, n_layers,verbose):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_len = embedding_dim\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # With pretrained embeddings\n",
        "        #weights = torch.FloatTensor(w2v_model.wv.vectors)\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
        "\n",
        "        # lstm\n",
        "        self.lstm = DBLSTM(self.embedding_len, self.hidden_dim, self.batch_size, seq_len, n_layers, verbose)\n",
        "        self.att = Att( 2*self.hidden_dim, self.batch_size, seq_len)\n",
        "\n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(2*self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        bs = x.size(0)\n",
        "        \n",
        "        # Embedding Layer\n",
        "        embeds = self.embedding(x)\n",
        "        embeds = embeds.float()\n",
        "        # LSTM Layer\n",
        "        y_t,y_net = self.lstm(embeds)\n",
        "        \n",
        "        #Attention\n",
        "        y_t = self.att(y_net)\n",
        "\n",
        "        #x = (x[:, -1, :])\n",
        "\n",
        "        # Fully connected Layer\n",
        "        out = self.fc(y_t)\n",
        "\n",
        "        # Sigmoid Function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(bs, -1)\n",
        "        \n",
        "\n",
        "        sig_out = sig_out[:, -1]  # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out\n",
        "def acc(pred, label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329e209e",
      "metadata": {
        "id": "329e209e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9590f164-2eaa-45e5-a57f-d1240d3e3b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(12189, 50)\n",
            "  (lstm): DBLSTM(\n",
            "    (lstm1): BILSTM()\n",
            "    (dlstm): ModuleList(\n",
            "      (0): BVLSTM()\n",
            "    )\n",
            "  )\n",
            "  (att): Att(\n",
            "    (softmax): Softmax(dim=0)\n",
            "  )\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "n_layers = 2\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "lr = 0.001\n",
        "vocab_len+=1\n",
        "verbose = True\n",
        "criterion = nn.BCELoss()\n",
        "model = SentimentRNN(weights, output_dim, vocab_len, hidden_dim, ED, batch_size, seq_len, n_layers,verbose)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92f3fe7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b92f3fe7",
        "outputId": "62392f8f-fd35-447d-ed99-0b3000900ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "Epoch 1\n",
            "train_loss : 0.7471551503453936 val_loss : 0.7024542927742005\n",
            "train_accuracy : 51.34285714285715 val_accuracy : 51.2\n",
            "Validation loss decreased (inf --> 0.702454).  Saving model ...\n",
            "==================================================\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "Epoch 2\n",
            "train_loss : 0.7054833020482745 val_loss : 0.6919752836227417\n",
            "train_accuracy : 49.94285714285714 val_accuracy : 48.8\n",
            "Validation loss decreased (0.702454 --> 0.691975).  Saving model ...\n",
            "==================================================\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "Epoch 3\n",
            "train_loss : 0.6993323905127389 val_loss : 0.6892332792282104\n",
            "train_accuracy : 50.25714285714285 val_accuracy : 51.2\n",
            "Validation loss decreased (0.691975 --> 0.689233).  Saving model ...\n",
            "==================================================\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "Epoch 4\n",
            "train_loss : 0.6931594797543117 val_loss : 0.6859125018119812\n",
            "train_accuracy : 53.28571428571428 val_accuracy : 57.199999999999996\n",
            "Validation loss decreased (0.689233 --> 0.685913).  Saving model ...\n",
            "==================================================\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fd5da6bdcf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-ce56754ad527>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# LSTM Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/SA/BILSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlstm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/SA/BILSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, init_states)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mg_t_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t_b\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_c_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t_b\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_c_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_c_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mo_t_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t_b\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_o_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t_b\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_o_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_o_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mc_t_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_t_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc_t_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi_t_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg_t_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mh_t_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_t_b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_t_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "valid_loss_min = np.Inf\n",
        "epoch_tr_loss, epoch_vl_loss = [], []\n",
        "epoch_tr_acc, epoch_vl_acc = [], []\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    count =0\n",
        "    for inputs, labels in train_loader:\n",
        "        #print(\"Epoch\",epoch,\"batch\",count+1)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        #print(inputs.shape)\n",
        "        #print(labels.shape)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        print(output.shape)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "        accuracy = acc(output, labels)\n",
        "        train_acc += accuracy\n",
        "        writer.add_scalar(\"Train Loss\", loss, epoch)\n",
        "        count+=1\n",
        "    writer.flush()\n",
        "    val_losses = []\n",
        "    val_acc = 0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        output = model(inputs)\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "        accuracy = acc(output, labels)\n",
        "        val_acc += accuracy\n",
        "        writer.add_scalar(\"Train Loss\", val_loss, epoch)\n",
        "    writer.flush()\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc / len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc / len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch + 1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc * 100} val_accuracy : {epoch_val_acc * 100}')\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), 'my_model_best_w2v.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25 * '==')\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4cbb36",
      "metadata": {
        "id": "cc4cbb36"
      },
      "outputs": [],
      "source": [
        "def test_results():\n",
        "    test_losses = []\n",
        "    test_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        output = model(inputs)\n",
        "        test_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "        test_losses.append(test_loss.item())\n",
        "\n",
        "        accuracy = acc(output, labels)\n",
        "        test_acc += accuracy\n",
        "    print(\"Test Accuracy : \", test_acc / len(test_loader.dataset))\n",
        "\n",
        "test_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Attention Module***\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class Att(nn.Module):\n",
        "  def __init__(self, hidden_size, batch_size, seq_len):\n",
        "        super().__init__()\n",
        "        self.input_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "\n",
        "        self.w = nn.Parameter(torch.Tensor(self.input_size))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.seq_len))\n",
        "        self.softmax = nn.Softmax(dim =0)\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "  def init_weight(self):\n",
        "      stdv = 1.0 / math.sqrt(self.seq_len)\n",
        "      for weights in self.parameters():\n",
        "          weights.data.uniform_(-stdv, stdv)\n",
        "\n",
        "  def forward(self,x):\n",
        "    et = torch.tanh(x @ self.w + self.b)\n",
        "    #print(et.shape)\n",
        "    at = self.softmax(et).unsqueeze(1)\n",
        "    #print(at.shape)\n",
        "    output = at @ x\n",
        "    output = output.squeeze(1)\n",
        "    #print(output.shape)\n",
        "    return output\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "SqbK0TzIpVXq"
      },
      "id": "SqbK0TzIpVXq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***BI LSTM***\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class BILSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, batch_size, seq_len):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        #Forward\n",
        "        # i_t\n",
        "        self.w_i = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_i = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_i = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # f_t\n",
        "        self.w_f = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_f = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_f = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # c_t\n",
        "        self.w_c = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_c = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_c = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # o_t\n",
        "        self.w_o = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_o = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_o = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        \n",
        "\n",
        "        #Forward\n",
        "        # i_t\n",
        "        self.w_i_b = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_i_b = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_i_b = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # f_t\n",
        "        self.w_f_b = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_f_b = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_f_b = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # c_t\n",
        "        self.w_c_b = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_c_b = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_c_b = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # o_t\n",
        "        self.w_o_b = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
        "        self.u_o_b = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_o_b = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weights in self.parameters():\n",
        "            weights.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x, init_states=None):\n",
        "        batch_size, seq_len = self.batch_size, self.seq_len\n",
        "        hidden_seq = []\n",
        "        hidden_seq_b = []\n",
        "        y_net = []\n",
        "        if init_states is None:\n",
        "            h_t = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "            c_t = torch.zeros(batch_size,self.hidden_size).to(x.device)\n",
        "            h_t_b = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "            c_t_b = torch.zeros(batch_size,self.hidden_size).to(x.device)\n",
        "        \n",
        "        else:\n",
        "            h_t, c_t, h_t_b, c_t_b = init_states\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            x_t = x[:, t, :]\n",
        "            i_t = torch.sigmoid(x_t @ self.w_i + h_t @ self.u_i + self.b_i)\n",
        "            f_t = torch.sigmoid(x_t @ self.w_f + h_t @ self.u_f + self.b_f)\n",
        "            g_t = torch.sigmoid(x_t @ self.w_c + h_t @ self.u_c + self.b_c)\n",
        "            o_t = torch.sigmoid(x_t @ self.w_o + h_t @ self.u_o + self.b_o)\n",
        "            c_t = f_t + c_t + i_t * g_t\n",
        "            h_t = o_t + torch.tanh(c_t)\n",
        "\n",
        "            x_t_b = x[:, seq_len-t-1, :]\n",
        "            i_t_b = torch.sigmoid(x_t_b @ self.w_i_b + h_t_b @ self.u_i_b + self.b_i_b)\n",
        "            f_t_b = torch.sigmoid(x_t_b @ self.w_f_b + h_t_b @ self.u_f_b + self.b_f_b)\n",
        "            g_t_b = torch.sigmoid(x_t_b @ self.w_c_b + h_t_b @ self.u_c_b + self.b_c_b)\n",
        "            o_t_b = torch.sigmoid(x_t_b @ self.w_o_b + h_t_b @ self.u_o_b + self.b_o_b)\n",
        "            c_t_b = f_t_b + c_t_b + i_t_b * g_t_b\n",
        "            h_t_b = o_t_b + torch.tanh(c_t_b)\n",
        "\n",
        "            hidden_seq.append(h_t.unsqueeze(0))\n",
        "            hidden_seq_b.append(h_t_b.unsqueeze(0))\n",
        "\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "        hidden_seq_b = torch.cat(hidden_seq_b, dim=0)\n",
        "        \n",
        "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
        "        hidden_seq_b = hidden_seq_b.transpose(0, 1).contiguous()\n",
        "        hidden_seq_b = torch.flip(hidden_seq_b,dims=(1,))\n",
        "        \n",
        "        y_net = torch.cat((hidden_seq,hidden_seq_b),dim=2)\n",
        "        y_t = torch.cat((h_t,h_t_b),dim=1)\n",
        "\n",
        "        return y_t, y_net\n",
        "    \n",
        "    \n",
        "class BVLSTM(nn.Module):\n",
        "    def __init__(self, input_size_x, input_size_h, hidden_size, batch_size, seq_len):\n",
        "        super().__init__()\n",
        "        self.input_size_x = input_size_x\n",
        "        self.input_size_h = input_size_h\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        # i_t\n",
        "        self.w_i_x = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_i_h = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_i = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_i = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # f_t\n",
        "        self.w_f_x = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_f_h = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_f = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_f = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # c_t\n",
        "        self.w_c_x = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_c_h = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_c = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_c = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # o_t\n",
        "        self.w_o_x = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_o_h = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_o = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_o = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "\n",
        "        #Backward\n",
        "        # i_t\n",
        "        self.w_i_x_b = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_i_h_b = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_i_b  = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_i_b  = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # f_t\n",
        "        self.w_f_x_b  = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_f_h_b  = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_f_b  = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_f_b  = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # c_t\n",
        "        self.w_c_x_b  = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_c_h_b = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_c_b  = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_c_b  = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        # o_t\n",
        "        self.w_o_x_b  = nn.Parameter(torch.Tensor(self.input_size_x, self.hidden_size))\n",
        "        self.w_o_h_b  = nn.Parameter(torch.Tensor(self.input_size_h, self.hidden_size))\n",
        "        self.u_o_b  = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.b_o_b  = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weights in self.parameters():\n",
        "            weights.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x, h_prev, init_states=None):\n",
        "        batch_size, seq_len = self.batch_size, self.seq_len\n",
        "        hidden_seq = []\n",
        "        hidden_seq_b = []\n",
        "        y_net = []\n",
        "        h_prev_b = h_prev[:,:,self.hidden_size:2*self.hidden_size]\n",
        "        h_prev = h_prev[:,:,0:self.hidden_size]\n",
        "\n",
        "        if init_states is None:\n",
        "            h_t, c_t = torch.zeros(batch_size, self.hidden_size).to(x.device), torch.zeros(batch_size,\n",
        "                                                                                           self.hidden_size).to(\n",
        "                x.device)\n",
        "            h_t_b = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "            c_t_b = torch.zeros(batch_size,self.hidden_size).to(x.device)\n",
        "        else:\n",
        "            h_t, c_t, h_t_b, c_t_b = init_states\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            x_t = x[:, t, :]\n",
        "            h_prev_t = h_prev[:, t, :]\n",
        "            i_t = torch.sigmoid(x_t @ self.w_i_x + h_prev_t @ self.w_i_h  + h_t @ self.u_i + self.b_i)\n",
        "            f_t = torch.sigmoid(x_t @ self.w_f_x + h_prev_t @ self.w_f_h  + h_t @ self.u_i + self.b_i)\n",
        "            g_t = torch.sigmoid(x_t @ self.w_c_x + h_prev_t @ self.w_c_h  + h_t @ self.u_i + self.b_i)\n",
        "            o_t = torch.sigmoid(x_t @ self.w_o_x + h_prev_t @ self.w_o_h  + h_t @ self.u_i + self.b_i)\n",
        "            c_t = f_t + c_t + i_t * g_t\n",
        "            h_t = o_t + torch.tanh(c_t)\n",
        "\n",
        "\n",
        "            x_t_b = x[:, seq_len-t-1, :]\n",
        "            h_prev_t_b = h_prev_b[:, seq_len-t-1, :]\n",
        "            i_t_b = torch.sigmoid(x_t_b @ self.w_i_x_b + h_prev_t_b @ self.w_i_h_b  + h_t_b @ self.u_i_b + self.b_i_b)\n",
        "            f_t_b = torch.sigmoid(x_t_b @ self.w_f_x_b + h_prev_t_b @ self.w_f_h_b  + h_t_b @ self.u_i_b + self.b_i_b)\n",
        "            g_t_b = torch.sigmoid(x_t_b @ self.w_c_x_b + h_prev_t_b @ self.w_c_h_b  + h_t_b @ self.u_i_b + self.b_i_b)\n",
        "            o_t_b = torch.sigmoid(x_t_b @ self.w_o_x_b + h_prev_t_b @ self.w_o_h_b  + h_t_b @ self.u_i_b + self.b_i_b)\n",
        "            c_t_b = f_t_b + c_t_b + i_t_b * g_t_b\n",
        "            h_t_b = o_t_b + torch.tanh(c_t_b)\n",
        "\n",
        "\n",
        "            hidden_seq.append(h_t.unsqueeze(0))\n",
        "            hidden_seq_b.append(h_t_b.unsqueeze(0))\n",
        "\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "        hidden_seq_b = torch.cat(hidden_seq_b, dim=0)\n",
        "        \n",
        "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
        "        hidden_seq_b = hidden_seq_b.transpose(0, 1).contiguous()\n",
        "        hidden_seq_b = torch.flip(hidden_seq_b,dims=(1,))\n",
        "        \n",
        "        y_net = torch.cat((hidden_seq,hidden_seq_b),dim=2)\n",
        "        y_t = torch.cat((h_t,h_t_b),dim=1)\n",
        "\n",
        "        return y_t, y_net\n",
        "\n",
        "\n",
        "class DBLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, batch_size, seq_len, n_layers, verbose  = True):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "        self.n_layers = n_layers\n",
        "        self.verbose = verbose\n",
        "        self.lstm1 = BILSTM(input_size, hidden_size, batch_size, seq_len)\n",
        "        \n",
        "        if self.verbose:\n",
        "            self.dlstm = nn.ModuleList(\n",
        "            [BVLSTM(input_size, hidden_size, hidden_size, batch_size, seq_len) for _ in range(self.n_layers-1)]\n",
        "            )\n",
        "        else:\n",
        "            self.dlstm = nn.ModuleList(\n",
        "            [BILSTM(hidden_size, hidden_size, batch_size, seq_len) for _ in range(self.n_layers-1)]\n",
        "            )\n",
        "            \n",
        "\n",
        "    def forward(self, x):\n",
        "        y_t, y_net = self.lstm1(x)\n",
        "        if self.verbose: \n",
        "            for lstm in self.dlstm:\n",
        "                y_t, y_net = lstm(x, y_net)\n",
        "        else:\n",
        "            for lstm in self.dlstm:\n",
        "                y_t, y_net = lstm(y_net)\n",
        "        return y_t, y_net\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "V4_sTXKDpVaP"
      },
      "id": "V4_sTXKDpVaP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***w2v.py***\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "def w2v_prep(df, df1, Embedding_dimensions=100):\n",
        "    review_text = df.review.apply(gensim.utils.simple_preprocess)\n",
        "    w2v_model = Word2Vec(review_text, vector_size=Embedding_dimensions, workers=8, min_count=5)\n",
        "    vocab_len = len(w2v_model.wv.key_to_index)\n",
        "    #print(w2v_model.wv.key_to_index)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(review_text,\n",
        "                                                        df1['sentiment'],\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=0)\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_train,\n",
        "                                                      Y_train,\n",
        "                                                      test_size=0.125,\n",
        "                                                      random_state=0)\n",
        "    return w2v_model, review_text, vocab_len, X_train, X_val, X_test, Y_train, Y_val, Y_test\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gkZdbYOQpVc1"
      },
      "id": "gkZdbYOQpVc1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "SA_Att.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}